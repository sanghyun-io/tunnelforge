"""
MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶„ì„ê¸°
- ê³ ì•„ ë ˆì½”ë“œ(orphan rows) íƒì§€
- FK ê´€ê³„ ë¶„ì„ ë° ì •ë¦¬
- MySQL 8.0.x â†’ 8.4.x í˜¸í™˜ì„± ê²€ì‚¬ (Upgrade Checker í†µí•©)
- dry-run ì§€ì›
- ë¤í”„ íŒŒì¼ ë¶„ì„ (SQL/TSV)
"""
import re
from typing import List, Dict, Set, Tuple, Optional, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from src.core.db_connector import MySQLConnector


# ============================================================
# MySQL 8.4 Upgrade Checker ìƒìˆ˜ (constants.tsì—ì„œ í¬íŒ…)
# ============================================================

# MySQL 8.4ì—ì„œ ì œê±°ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜ (47ê°œ)
REMOVED_SYS_VARS_84 = (
    'avoid_temporal_upgrade',
    'binlog_transaction_dependency_tracking',
    'default_authentication_plugin',
    'group_replication_ip_allowlist',
    'group_replication_recovery_complete_at',
    'have_openssl',
    'have_ssl',
    'innodb_log_file_size',
    'innodb_log_files_in_group',
    'keyring_file_data',
    'keyring_file_data_file',
    'keyring_encrypted_file_data',
    'keyring_encrypted_file_password',
    'keyring_okv_conf_dir',
    'keyring_hashicorp_auth_path',
    'keyring_hashicorp_ca_path',
    'keyring_hashicorp_caching',
    'keyring_hashicorp_commit_auth_path',
    'keyring_hashicorp_commit_caching',
    'keyring_hashicorp_commit_role_id',
    'keyring_hashicorp_commit_server_url',
    'keyring_hashicorp_commit_store_path',
    'keyring_hashicorp_role_id',
    'keyring_hashicorp_secret_id',
    'keyring_hashicorp_server_url',
    'keyring_hashicorp_store_path',
    'keyring_aws_cmk_id',
    'keyring_aws_conf_file',
    'keyring_aws_data_file',
    'keyring_aws_region',
    'log_bin_use_v1_row_events',
    'master_verify_checksum',
    'old_alter_table',
    'relay_log_info_file',
    'relay_log_info_repository',
    'replica_parallel_type',
    'slave_parallel_type',
    'slave_rows_search_algorithms',
    'sql_slave_skip_counter',
    'sync_master_info',
    'sync_relay_log',
    'sync_relay_log_info',
    'transaction_write_set_extraction',
    'binlog_format',
    'log_slave_updates',
    'replica_compressed_protocol',
    'slave_compressed_protocol',
)

# MySQL 8.4ì—ì„œ ì¶”ê°€ëœ ìƒˆ ì˜ˆì•½ì–´ (4ê°œ)
NEW_RESERVED_KEYWORDS_84 = ('MANUAL', 'PARALLEL', 'QUALIFY', 'TABLESAMPLE')

# MySQL 8.4ì—ì„œ ì œê±°ëœ í•¨ìˆ˜ (6ê°œ) - ê¸°ì¡´ DEPRECATED_FUNCTIONSì™€ ë³‘í•©
REMOVED_FUNCTIONS_84 = (
    'PASSWORD', 'ENCODE', 'DECODE', 'DES_ENCRYPT', 'DES_DECRYPT',
    'ENCRYPT', 'OLD_PASSWORD', 'MASTER_POS_WAIT'
)

# ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ
AUTH_PLUGINS = {
    'disabled': ['mysql_native_password'],  # 8.4ì—ì„œ ê¸°ë³¸ ë¹„í™œì„±í™”
    'removed': ['authentication_fido', 'authentication_fido_client'],  # 8.4ì—ì„œ ì œê±°
    'deprecated': ['sha256_password'],  # deprecated, caching_sha2_password ê¶Œì¥
}

# ì œê±°ëœ/deprecated SQL ëª¨ë“œ (10ê°œ)
OBSOLETE_SQL_MODES = (
    'DB2', 'MAXDB', 'MSSQL', 'MYSQL323', 'MYSQL40',
    'ORACLE', 'POSTGRESQL', 'NO_FIELD_OPTIONS', 'NO_KEY_OPTIONS',
    'NO_TABLE_OPTIONS', 'NO_AUTO_CREATE_USER',
)

# ê¸°ë³¸ê°’ì´ ë³€ê²½ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜
SYS_VARS_NEW_DEFAULTS_84 = {
    'binlog_transaction_dependency_tracking': {
        'old': 'COMMIT_ORDER', 'new': 'removed (use replica_parallel_type)',
    },
    'replica_parallel_workers': {
        'old': '0', 'new': '4',
    },
    'innodb_adaptive_hash_index': {
        'old': 'ON', 'new': 'OFF',
    },
    'innodb_doublewrite_pages': {
        'old': '(innodb_write_io_threads)', 'new': '128',
    },
    'innodb_flush_method': {
        'old': 'fsync (Unix)', 'new': 'O_DIRECT (Linux)',
    },
    'innodb_io_capacity': {
        'old': '200', 'new': '10000',
    },
    'innodb_io_capacity_max': {
        'old': '2 * innodb_io_capacity', 'new': '2 * new default',
    },
    'innodb_log_buffer_size': {
        'old': '16M', 'new': '64M',
    },
    'innodb_redo_log_capacity': {
        'old': '100M', 'new': '100M (now replaces log_file_size * files)',
    },
    'group_replication_consistency': {
        'old': 'EVENTUAL', 'new': 'BEFORE_ON_PRIMARY_FAILOVER',
    },
}

# ============================================================
# ë¤í”„ íŒŒì¼ ë¶„ì„ìš© ì •ê·œì‹ íŒ¨í„´ (rules.tsì—ì„œ í¬íŒ…)
# ============================================================

# 0000-00-00 ë‚ ì§œ (ì˜ëª»ëœ ë‚ ì§œ)
INVALID_DATE_PATTERN = re.compile(r"['\"]0000-00-00['\"]|^0000-00-00$", re.MULTILINE)
INVALID_DATETIME_PATTERN = re.compile(r"['\"]0000-00-00 00:00:00['\"]|^0000-00-00 00:00:00$", re.MULTILINE)

# ZEROFILL ì†ì„±
ZEROFILL_PATTERN = re.compile(r'\bZEROFILL\b', re.IGNORECASE)

# FLOAT(M,D), DOUBLE(M,D) êµ¬ë¬¸ (deprecated)
FLOAT_PRECISION_PATTERN = re.compile(
    r'\b(FLOAT|DOUBLE|REAL)\s*\(\s*\d+\s*,\s*\d+\s*\)',
    re.IGNORECASE
)

# INT í‘œì‹œ ë„ˆë¹„ (deprecated, TINYINT(1) ì œì™¸)
INT_DISPLAY_WIDTH_PATTERN = re.compile(
    r'\b(TINYINT|SMALLINT|MEDIUMINT|INT|INTEGER|BIGINT)\s*\(\s*(\d+)\s*\)',
    re.IGNORECASE
)

# FK ì´ë¦„ ê¸¸ì´ (64ì ì´ˆê³¼)
FK_NAME_LENGTH_PATTERN = re.compile(
    r'CONSTRAINT\s+`?(\w{65,})`?\s+FOREIGN\s+KEY',
    re.IGNORECASE
)

# mysql_native_password ì¸ì¦ í”ŒëŸ¬ê·¸ì¸
AUTH_PLUGIN_PATTERN = re.compile(
    r"IDENTIFIED\s+(?:WITH\s+)?['\"]?(mysql_native_password|sha256_password|authentication_fido)['\"]?",
    re.IGNORECASE
)

# FTS_ ì ‘ë‘ì‚¬ í…Œì´ë¸”ëª… (ë‚´ë¶€ ì˜ˆì•½)
FTS_TABLE_PREFIX_PATTERN = re.compile(r'CREATE\s+TABLE\s+`?FTS_', re.IGNORECASE)

# GRANT ë¬¸ì˜ SUPER ê¶Œí•œ
SUPER_PRIVILEGE_PATTERN = re.compile(r'\bGRANT\b.*\bSUPER\b', re.IGNORECASE)

# ì œê±°ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜ ì‚¬ìš© (SET/SELECT ë¬¸ì—ì„œ)
SYS_VAR_USAGE_PATTERN = re.compile(
    r"(?:SET|SELECT)\s+.*(?:@@(?:global|session)?\.)?" +
    r"(" + "|".join(re.escape(v) for v in REMOVED_SYS_VARS_84) + r")\b",
    re.IGNORECASE
)


class IssueType(Enum):
    """ë¬¸ì œ ìœ í˜•"""
    # ê¸°ì¡´ ì´ìŠˆ íƒ€ì…
    ORPHAN_ROW = "orphan_row"  # ë¶€ëª¨ ì—†ëŠ” ìì‹ ë ˆì½”ë“œ
    DEPRECATED_FUNCTION = "deprecated_function"  # deprecated í•¨ìˆ˜ ì‚¬ìš©
    CHARSET_ISSUE = "charset_issue"  # utf8mb3 â†’ utf8mb4 í•„ìš”
    RESERVED_KEYWORD = "reserved_keyword"  # ì˜ˆì•½ì–´ ì¶©ëŒ
    SQL_MODE_ISSUE = "sql_mode_issue"  # deprecated SQL ëª¨ë“œ

    # MySQL 8.4 Upgrade Checker ì´ìŠˆ íƒ€ì… (ì‹ ê·œ)
    REMOVED_SYS_VAR = "removed_sys_var"  # ì œê±°ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜
    AUTH_PLUGIN_ISSUE = "auth_plugin_issue"  # ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ì´ìŠˆ
    INVALID_DATE = "invalid_date"  # 0000-00-00 ë‚ ì§œ
    ZEROFILL_USAGE = "zerofill_usage"  # ZEROFILL ì†ì„±
    FLOAT_PRECISION = "float_precision"  # FLOAT(M,D) êµ¬ë¬¸
    INT_DISPLAY_WIDTH = "int_display_width"  # INT(11) í‘œì‹œ ë„ˆë¹„
    FK_NAME_LENGTH = "fk_name_length"  # FK ì´ë¦„ 64ì ì´ˆê³¼
    FTS_TABLE_PREFIX = "fts_table_prefix"  # FTS_ í…Œì´ë¸”ëª…
    SUPER_PRIVILEGE = "super_privilege"  # SUPER ê¶Œí•œ ì‚¬ìš©
    DEFAULT_VALUE_CHANGE = "default_value_change"  # ê¸°ë³¸ê°’ ë³€ê²½ë¨


class ActionType(Enum):
    """ì¡°ì¹˜ ìœ í˜•"""
    DELETE = "delete"  # ì‚­ì œ
    UPDATE = "update"  # ì—…ë°ì´íŠ¸
    SET_NULL = "set_null"  # NULLë¡œ ì„¤ì •
    MANUAL = "manual"  # ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”


@dataclass
class OrphanRecord:
    """ê³ ì•„ ë ˆì½”ë“œ ì •ë³´"""
    child_table: str
    child_column: str
    parent_table: str
    parent_column: str
    orphan_count: int
    sample_values: List[Any] = field(default_factory=list)


@dataclass
class ForeignKeyInfo:
    """FK ê´€ê³„ ì •ë³´"""
    constraint_name: str
    child_table: str
    child_column: str
    parent_table: str
    parent_column: str
    on_delete: str
    on_update: str


@dataclass
class CompatibilityIssue:
    """í˜¸í™˜ì„± ë¬¸ì œ"""
    issue_type: IssueType
    severity: str  # "error", "warning", "info"
    location: str  # í…Œì´ë¸”ëª… ë˜ëŠ” ìœ„ì¹˜
    description: str
    suggestion: str


@dataclass
class CleanupAction:
    """ì •ë¦¬ ì‘ì—…"""
    action_type: ActionType
    table: str
    description: str
    sql: str
    affected_rows: int
    dry_run: bool = True


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    schema: str
    analyzed_at: str
    total_tables: int
    total_fk_relations: int
    orphan_records: List[OrphanRecord] = field(default_factory=list)
    compatibility_issues: List[CompatibilityIssue] = field(default_factory=list)
    cleanup_actions: List[CleanupAction] = field(default_factory=list)
    fk_tree: Dict[str, List[str]] = field(default_factory=dict)


class MigrationAnalyzer:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶„ì„ê¸°"""

    # MySQL 8.4ì—ì„œ ì œê±°ëœ/deprecatedëœ í•¨ìˆ˜ë“¤ (ì „ì—­ ìƒìˆ˜ ì‚¬ìš©)
    DEPRECATED_FUNCTIONS = list(REMOVED_FUNCTIONS_84)

    # MySQL 8.4ì—ì„œ ìƒˆë¡œìš´ ì˜ˆì•½ì–´ë“¤ (ê¸°ì¡´ 22ê°œ + 8.4 ì¶”ê°€ 4ê°œ)
    NEW_RESERVED_KEYWORDS = [
        'CUME_DIST', 'DENSE_RANK', 'EMPTY', 'EXCEPT', 'FIRST_VALUE',
        'GROUPING', 'GROUPS', 'JSON_TABLE', 'LAG', 'LAST_VALUE', 'LATERAL',
        'LEAD', 'NTH_VALUE', 'NTILE', 'OF', 'OVER', 'PERCENT_RANK',
        'RANK', 'RECURSIVE', 'ROW_NUMBER', 'SYSTEM', 'WINDOW',
        # MySQL 8.4 ì¶”ê°€ ì˜ˆì•½ì–´
        'MANUAL', 'PARALLEL', 'QUALIFY', 'TABLESAMPLE'
    ]

    def __init__(self, connector: MySQLConnector):
        self.connector = connector
        self._progress_callback: Optional[Callable[[str], None]] = None

    def set_progress_callback(self, callback: Callable[[str], None]):
        """ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì •"""
        self._progress_callback = callback

    def _log(self, message: str):
        """ì§„í–‰ ìƒí™© ë¡œê¹…"""
        if self._progress_callback:
            self._progress_callback(message)

    def get_foreign_keys(self, schema: str) -> List[ForeignKeyInfo]:
        """ìŠ¤í‚¤ë§ˆì˜ ëª¨ë“  FK ê´€ê³„ ì¡°íšŒ"""
        query = """
        SELECT
            tc.CONSTRAINT_NAME,
            kcu.TABLE_NAME as CHILD_TABLE,
            kcu.COLUMN_NAME as CHILD_COLUMN,
            kcu.REFERENCED_TABLE_NAME as PARENT_TABLE,
            kcu.REFERENCED_COLUMN_NAME as PARENT_COLUMN,
            rc.DELETE_RULE,
            rc.UPDATE_RULE
        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS tc
        JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu
            ON tc.CONSTRAINT_NAME = kcu.CONSTRAINT_NAME
            AND tc.TABLE_SCHEMA = kcu.TABLE_SCHEMA
        JOIN INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS rc
            ON tc.CONSTRAINT_NAME = rc.CONSTRAINT_NAME
            AND tc.TABLE_SCHEMA = rc.CONSTRAINT_SCHEMA
        WHERE tc.TABLE_SCHEMA = %s
            AND tc.CONSTRAINT_TYPE = 'FOREIGN KEY'
        ORDER BY kcu.TABLE_NAME, kcu.COLUMN_NAME
        """
        rows = self.connector.execute(query, (schema,))

        fk_list = []
        for row in rows:
            fk_list.append(ForeignKeyInfo(
                constraint_name=row['CONSTRAINT_NAME'],
                child_table=row['CHILD_TABLE'],
                child_column=row['CHILD_COLUMN'],
                parent_table=row['PARENT_TABLE'],
                parent_column=row['PARENT_COLUMN'],
                on_delete=row['DELETE_RULE'],
                on_update=row['UPDATE_RULE']
            ))

        return fk_list

    def build_fk_tree(self, schema: str) -> Dict[str, List[str]]:
        """FK ê´€ê³„ íŠ¸ë¦¬ êµ¬ì„± (ë¶€ëª¨ â†’ ìì‹ ëª©ë¡)"""
        fk_list = self.get_foreign_keys(schema)

        tree = {}
        for fk in fk_list:
            if fk.parent_table not in tree:
                tree[fk.parent_table] = []
            if fk.child_table not in tree[fk.parent_table]:
                tree[fk.parent_table].append(fk.child_table)

        return tree

    def find_orphan_records(
        self,
        schema: str,
        sample_limit: int = 5
    ) -> List[OrphanRecord]:
        """ê³ ì•„ ë ˆì½”ë“œ íƒì§€ (ë¶€ëª¨ ì—†ëŠ” ìì‹ ë ˆì½”ë“œ)"""
        self._log("ğŸ” ê³ ì•„ ë ˆì½”ë“œ íƒì§€ ì¤‘...")

        fk_list = self.get_foreign_keys(schema)
        orphans = []

        for i, fk in enumerate(fk_list, 1):
            self._log(f"  ê²€ì‚¬ ì¤‘: {fk.child_table}.{fk.child_column} â†’ {fk.parent_table}.{fk.parent_column} ({i}/{len(fk_list)})")

            # ê³ ì•„ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            count_query = f"""
            SELECT COUNT(*) as cnt
            FROM `{schema}`.`{fk.child_table}` c
            LEFT JOIN `{schema}`.`{fk.parent_table}` p
                ON c.`{fk.child_column}` = p.`{fk.parent_column}`
            WHERE c.`{fk.child_column}` IS NOT NULL
                AND p.`{fk.parent_column}` IS NULL
            """
            result = self.connector.execute(count_query)
            orphan_count = result[0]['cnt'] if result else 0

            if orphan_count > 0:
                # ìƒ˜í”Œ ê°’ ì¡°íšŒ
                sample_query = f"""
                SELECT DISTINCT c.`{fk.child_column}` as orphan_value
                FROM `{schema}`.`{fk.child_table}` c
                LEFT JOIN `{schema}`.`{fk.parent_table}` p
                    ON c.`{fk.child_column}` = p.`{fk.parent_column}`
                WHERE c.`{fk.child_column}` IS NOT NULL
                    AND p.`{fk.parent_column}` IS NULL
                LIMIT {sample_limit}
                """
                samples = self.connector.execute(sample_query)
                sample_values = [s['orphan_value'] for s in samples]

                orphans.append(OrphanRecord(
                    child_table=fk.child_table,
                    child_column=fk.child_column,
                    parent_table=fk.parent_table,
                    parent_column=fk.parent_column,
                    orphan_count=orphan_count,
                    sample_values=sample_values
                ))

                self._log(f"    âš ï¸ ê³ ì•„ ë ˆì½”ë“œ ë°œê²¬: {orphan_count}ê°œ")

        return orphans

    def check_charset_issues(self, schema: str) -> List[CompatibilityIssue]:
        """utf8mb3 ì‚¬ìš© í…Œì´ë¸”/ì»¬ëŸ¼ í™•ì¸"""
        self._log("ğŸ” ë¬¸ìì…‹ ì´ìŠˆ í™•ì¸ ì¤‘...")

        issues = []

        # í…Œì´ë¸” ë ˆë²¨ charset í™•ì¸
        table_query = """
        SELECT TABLE_NAME, TABLE_COLLATION
        FROM INFORMATION_SCHEMA.TABLES
        WHERE TABLE_SCHEMA = %s
            AND TABLE_TYPE = 'BASE TABLE'
            AND (TABLE_COLLATION LIKE 'utf8_%%' OR TABLE_COLLATION LIKE 'utf8mb3_%%')
        """
        tables = self.connector.execute(table_query, (schema,))

        for t in tables:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.CHARSET_ISSUE,
                severity="warning",
                location=f"{schema}.{t['TABLE_NAME']}",
                description=f"í…Œì´ë¸”ì´ utf8mb3 collation ì‚¬ìš© ì¤‘: {t['TABLE_COLLATION']}",
                suggestion="ALTER TABLE ... CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
            ))

        # ì»¬ëŸ¼ ë ˆë²¨ charset í™•ì¸
        column_query = """
        SELECT TABLE_NAME, COLUMN_NAME, CHARACTER_SET_NAME, COLLATION_NAME
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
            AND CHARACTER_SET_NAME IN ('utf8', 'utf8mb3')
        """
        columns = self.connector.execute(column_query, (schema,))

        for c in columns:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.CHARSET_ISSUE,
                severity="warning",
                location=f"{schema}.{c['TABLE_NAME']}.{c['COLUMN_NAME']}",
                description=f"ì»¬ëŸ¼ì´ utf8mb3 ì‚¬ìš© ì¤‘: {c['CHARACTER_SET_NAME']}",
                suggestion="ALTER TABLE ... MODIFY COLUMN ... CHARACTER SET utf8mb4"
            ))

        if issues:
            self._log(f"  âš ï¸ ë¬¸ìì…‹ ì´ìŠˆ {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… ë¬¸ìì…‹ ì´ìŠˆ ì—†ìŒ")

        return issues

    def check_reserved_keywords(self, schema: str) -> List[CompatibilityIssue]:
        """ì˜ˆì•½ì–´ì™€ ì¶©ëŒí•˜ëŠ” ì»¬ëŸ¼/í…Œì´ë¸”ëª… í™•ì¸"""
        self._log("ğŸ” ì˜ˆì•½ì–´ ì¶©ëŒ í™•ì¸ ì¤‘...")

        issues = []
        keywords_upper = set(k.upper() for k in self.NEW_RESERVED_KEYWORDS)

        # í…Œì´ë¸”ëª… í™•ì¸
        tables = self.connector.get_tables(schema)
        for table in tables:
            if table.upper() in keywords_upper:
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.RESERVED_KEYWORD,
                    severity="error",
                    location=f"{schema}.{table}",
                    description=f"í…Œì´ë¸”ëª… '{table}'ì´ MySQL 8.4 ì˜ˆì•½ì–´ì™€ ì¶©ëŒ",
                    suggestion=f"í…Œì´ë¸”ëª…ì„ ë°±í‹±ìœ¼ë¡œ ê°ì‹¸ê±°ë‚˜ ì´ë¦„ ë³€ê²½ í•„ìš”"
                ))

        # ì»¬ëŸ¼ëª… í™•ì¸
        column_query = """
        SELECT TABLE_NAME, COLUMN_NAME
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
        """
        columns = self.connector.execute(column_query, (schema,))

        for c in columns:
            if c['COLUMN_NAME'].upper() in keywords_upper:
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.RESERVED_KEYWORD,
                    severity="warning",
                    location=f"{schema}.{c['TABLE_NAME']}.{c['COLUMN_NAME']}",
                    description=f"ì»¬ëŸ¼ëª… '{c['COLUMN_NAME']}'ì´ MySQL 8.4 ì˜ˆì•½ì–´ì™€ ì¶©ëŒ",
                    suggestion="ì»¬ëŸ¼ ì°¸ì¡° ì‹œ ë°±í‹±(`) ì‚¬ìš© í•„ìš”"
                ))

        if issues:
            self._log(f"  âš ï¸ ì˜ˆì•½ì–´ ì¶©ëŒ {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… ì˜ˆì•½ì–´ ì¶©ëŒ ì—†ìŒ")

        return issues

    def check_deprecated_in_routines(self, schema: str) -> List[CompatibilityIssue]:
        """ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ì—ì„œ deprecated í•¨ìˆ˜ ì‚¬ìš© í™•ì¸"""
        self._log("ğŸ” ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ ê²€ì‚¬ ì¤‘...")

        issues = []

        # ì €ì¥ í”„ë¡œì‹œì €ì™€ í•¨ìˆ˜ ì¡°íšŒ
        routine_query = """
        SELECT ROUTINE_NAME, ROUTINE_TYPE, ROUTINE_DEFINITION
        FROM INFORMATION_SCHEMA.ROUTINES
        WHERE ROUTINE_SCHEMA = %s
            AND ROUTINE_DEFINITION IS NOT NULL
        """
        routines = self.connector.execute(routine_query, (schema,))

        for routine in routines:
            definition = routine['ROUTINE_DEFINITION'].upper() if routine['ROUTINE_DEFINITION'] else ""

            for func in self.DEPRECATED_FUNCTIONS:
                if func in definition:
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.DEPRECATED_FUNCTION,
                        severity="error",
                        location=f"{routine['ROUTINE_TYPE']} {schema}.{routine['ROUTINE_NAME']}",
                        description=f"deprecated í•¨ìˆ˜ '{func}' ì‚¬ìš© ì¤‘",
                        suggestion=f"'{func}' í•¨ìˆ˜ë¥¼ ëŒ€ì²´ í•¨ìˆ˜ë¡œ ë³€ê²½ í•„ìš”"
                    ))

        if issues:
            self._log(f"  âš ï¸ deprecated í•¨ìˆ˜ ì‚¬ìš© {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… deprecated í•¨ìˆ˜ ì—†ìŒ")

        return issues

    def check_sql_modes(self) -> List[CompatibilityIssue]:
        """í˜„ì¬ SQL ëª¨ë“œ í™•ì¸"""
        self._log("ğŸ” SQL ëª¨ë“œ í™•ì¸ ì¤‘...")

        issues = []

        # deprecated SQL ëª¨ë“œë“¤
        deprecated_modes = [
            'NO_AUTO_CREATE_USER',  # 8.0ì—ì„œ ì œê±°ë¨
            'NO_FIELD_OPTIONS',
            'NO_KEY_OPTIONS',
            'NO_TABLE_OPTIONS',
        ]

        result = self.connector.execute("SELECT @@sql_mode as sql_mode")
        if result:
            current_modes = result[0]['sql_mode'].split(',')

            for mode in current_modes:
                mode = mode.strip()
                if mode in deprecated_modes:
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.SQL_MODE_ISSUE,
                        severity="warning",
                        location="@@sql_mode",
                        description=f"deprecated SQL ëª¨ë“œ '{mode}' ì‚¬ìš© ì¤‘",
                        suggestion=f"sql_modeì—ì„œ '{mode}' ì œê±° í•„ìš”"
                    ))

        if issues:
            self._log(f"  âš ï¸ deprecated SQL ëª¨ë“œ {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… SQL ëª¨ë“œ ì •ìƒ")

        return issues

    def generate_cleanup_sql(
        self,
        orphan: OrphanRecord,
        action: ActionType,
        schema: str,
        dry_run: bool = True
    ) -> CleanupAction:
        """ê³ ì•„ ë ˆì½”ë“œ ì •ë¦¬ SQL ìƒì„±"""
        if action == ActionType.DELETE:
            sql = f"""DELETE FROM `{schema}`.`{orphan.child_table}`
WHERE `{orphan.child_column}` NOT IN (
    SELECT `{orphan.parent_column}` FROM `{schema}`.`{orphan.parent_table}`
)
AND `{orphan.child_column}` IS NOT NULL"""
            description = f"{orphan.child_table}ì—ì„œ ê³ ì•„ ë ˆì½”ë“œ {orphan.orphan_count}ê°œ ì‚­ì œ"

        elif action == ActionType.SET_NULL:
            sql = f"""UPDATE `{schema}`.`{orphan.child_table}`
SET `{orphan.child_column}` = NULL
WHERE `{orphan.child_column}` NOT IN (
    SELECT `{orphan.parent_column}` FROM `{schema}`.`{orphan.parent_table}`
)
AND `{orphan.child_column}` IS NOT NULL"""
            description = f"{orphan.child_table}.{orphan.child_column}ì„ NULLë¡œ ì„¤ì • ({orphan.orphan_count}ê°œ)"

        else:
            sql = f"-- ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”: {orphan.child_table}.{orphan.child_column}"
            description = f"{orphan.child_table} ìˆ˜ë™ ê²€í†  í•„ìš”"

        return CleanupAction(
            action_type=action,
            table=orphan.child_table,
            description=description,
            sql=sql,
            affected_rows=orphan.orphan_count,
            dry_run=dry_run
        )

    def execute_cleanup(
        self,
        action: CleanupAction,
        dry_run: bool = True
    ) -> Tuple[bool, str, int]:
        """
        ì •ë¦¬ ì‘ì—… ì‹¤í–‰

        Args:
            action: ì‹¤í–‰í•  ì •ë¦¬ ì‘ì—…
            dry_run: Trueë©´ ì‹¤ì œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì˜í–¥ë°›ëŠ” í–‰ ìˆ˜ë§Œ ë°˜í™˜

        Returns:
            (ì„±ê³µì—¬ë¶€, ë©”ì‹œì§€, ì˜í–¥ë°›ì€ í–‰ ìˆ˜)
        """
        if dry_run:
            # dry-run: ì‹¤ì œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì˜í–¥ë°›ëŠ” í–‰ ìˆ˜ í™•ì¸
            self._log(f"ğŸ” [DRY-RUN] ì˜í–¥ ë¶„ì„: {action.table}")

            if action.action_type == ActionType.MANUAL:
                return True, "ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”", 0

            # COUNT ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì˜í–¥ë°›ëŠ” í–‰ ìˆ˜ í™•ì¸
            # DELETE/UPDATEì˜ WHERE ì ˆ ì¶”ì¶œ
            sql_upper = action.sql.upper()
            if 'WHERE' in sql_upper:
                where_idx = action.sql.upper().find('WHERE')
                where_clause = action.sql[where_idx:]

                # í…Œì´ë¸”ëª… ì¶”ì¶œ
                if action.action_type == ActionType.DELETE:
                    # DELETE FROM `schema`.`table` WHERE ...
                    count_sql = f"SELECT COUNT(*) as cnt FROM {action.sql.split('FROM')[1].split('WHERE')[0].strip()} {where_clause}"
                else:
                    # UPDATE `schema`.`table` SET ... WHERE ...
                    count_sql = f"SELECT COUNT(*) as cnt FROM {action.sql.split('UPDATE')[1].split('SET')[0].strip()} {where_clause}"

                result = self.connector.execute(count_sql)
                affected = result[0]['cnt'] if result else 0

                return True, f"[DRY-RUN] {affected}ê°œ í–‰ì´ ì˜í–¥ë°›ìŒ", affected

            return True, "[DRY-RUN] ì˜í–¥ ë¶„ì„ ì™„ë£Œ", action.affected_rows

        else:
            # ì‹¤ì œ ì‹¤í–‰
            self._log(f"ğŸ”§ ì‹¤í–‰ ì¤‘: {action.table}")

            try:
                with self.connector.connection.cursor() as cursor:
                    cursor.execute(action.sql)
                    affected = cursor.rowcount
                    self.connector.connection.commit()

                return True, f"âœ… {affected}ê°œ í–‰ ì²˜ë¦¬ë¨", affected

            except Exception as e:
                self.connector.connection.rollback()
                return False, f"âŒ ì˜¤ë¥˜: {str(e)}", 0

    def analyze_schema(
        self,
        schema: str,
        check_orphans: bool = True,
        check_charset: bool = True,
        check_keywords: bool = True,
        check_routines: bool = True,
        check_sql_mode: bool = True,
        check_auth_plugins: bool = True,
        check_zerofill: bool = True,
        check_float_precision: bool = True,
        check_fk_name_length: bool = True
    ) -> AnalysisResult:
        """
        ìŠ¤í‚¤ë§ˆ ì „ì²´ ë¶„ì„

        Args:
            schema: ë¶„ì„í•  ìŠ¤í‚¤ë§ˆëª…
            check_orphans: ê³ ì•„ ë ˆì½”ë“œ ê²€ì‚¬ ì—¬ë¶€
            check_charset: ë¬¸ìì…‹ ì´ìŠˆ ê²€ì‚¬ ì—¬ë¶€
            check_keywords: ì˜ˆì•½ì–´ ì¶©ëŒ ê²€ì‚¬ ì—¬ë¶€
            check_routines: ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ ê²€ì‚¬ ì—¬ë¶€
            check_sql_mode: SQL ëª¨ë“œ ê²€ì‚¬ ì—¬ë¶€
            check_auth_plugins: ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ê²€ì‚¬ ì—¬ë¶€
            check_zerofill: ZEROFILL ì†ì„± ê²€ì‚¬ ì—¬ë¶€
            check_float_precision: FLOAT(M,D) êµ¬ë¬¸ ê²€ì‚¬ ì—¬ë¶€
            check_fk_name_length: FK ì´ë¦„ ê¸¸ì´ ê²€ì‚¬ ì—¬ë¶€

        Returns:
            AnalysisResult
        """
        from datetime import datetime

        self._log(f"ğŸ“Š ìŠ¤í‚¤ë§ˆ '{schema}' ë¶„ì„ ì‹œì‘...")

        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        tables = self.connector.get_tables(schema)
        fk_list = self.get_foreign_keys(schema)
        fk_tree = self.build_fk_tree(schema)

        self._log(f"  í…Œì´ë¸” ìˆ˜: {len(tables)}, FK ê´€ê³„: {len(fk_list)}")

        result = AnalysisResult(
            schema=schema,
            analyzed_at=datetime.now().isoformat(),
            total_tables=len(tables),
            total_fk_relations=len(fk_list),
            fk_tree=fk_tree
        )

        # ê³ ì•„ ë ˆì½”ë“œ ê²€ì‚¬
        if check_orphans and fk_list:
            result.orphan_records = self.find_orphan_records(schema)

        # í˜¸í™˜ì„± ê²€ì‚¬ë“¤ (ê¸°ì¡´)
        if check_charset:
            result.compatibility_issues.extend(self.check_charset_issues(schema))

        if check_keywords:
            result.compatibility_issues.extend(self.check_reserved_keywords(schema))

        if check_routines:
            result.compatibility_issues.extend(self.check_deprecated_in_routines(schema))

        if check_sql_mode:
            result.compatibility_issues.extend(self.check_sql_modes())

        # MySQL 8.4 Upgrade Checker ê²€ì‚¬ë“¤ (ì‹ ê·œ)
        if check_auth_plugins:
            result.compatibility_issues.extend(self.check_auth_plugins())

        if check_zerofill:
            result.compatibility_issues.extend(self.check_zerofill_columns(schema))

        if check_float_precision:
            result.compatibility_issues.extend(self.check_float_precision(schema))

        if check_fk_name_length:
            result.compatibility_issues.extend(self.check_fk_name_length(schema))

        # ì •ë¦¬ ì‘ì—… ìƒì„± (ê³ ì•„ ë ˆì½”ë“œì— ëŒ€í•´)
        for orphan in result.orphan_records:
            # ê¸°ë³¸ì ìœ¼ë¡œ DELETE ì‘ì—… ìƒì„± (dry-run)
            cleanup = self.generate_cleanup_sql(orphan, ActionType.DELETE, schema, dry_run=True)
            result.cleanup_actions.append(cleanup)

        self._log(f"âœ… ë¶„ì„ ì™„ë£Œ")
        self._log(f"  - ê³ ì•„ ë ˆì½”ë“œ: {len(result.orphan_records)}ê°œ FK ê´€ê³„ì—ì„œ ë°œê²¬")
        self._log(f"  - í˜¸í™˜ì„± ì´ìŠˆ: {len(result.compatibility_issues)}ê°œ")

        return result

    # ============================================================
    # MySQL 8.4 Upgrade Checker ê²€ì‚¬ ë©”ì„œë“œë“¤ (ì‹ ê·œ)
    # ============================================================

    def check_auth_plugins(self) -> List[CompatibilityIssue]:
        """mysql_native_password, sha256_password ì‚¬ìš©ì í™•ì¸"""
        self._log("ğŸ” ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘...")

        issues = []

        # ì‚¬ìš©ìë³„ ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ì¡°íšŒ
        query = """
        SELECT User, Host, plugin
        FROM mysql.user
        WHERE plugin IN ('mysql_native_password', 'sha256_password', 'authentication_fido')
        """
        try:
            users = self.connector.execute(query)

            for user in users:
                plugin = user['plugin']

                if plugin == 'mysql_native_password':
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.AUTH_PLUGIN_ISSUE,
                        severity="error",
                        location=f"'{user['User']}'@'{user['Host']}'",
                        description=f"mysql_native_password ì¸ì¦ ì‚¬ìš© (8.4ì—ì„œ ê¸°ë³¸ ë¹„í™œì„±í™”)",
                        suggestion="ALTER USER ... IDENTIFIED WITH caching_sha2_password"
                    ))
                elif plugin == 'sha256_password':
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.AUTH_PLUGIN_ISSUE,
                        severity="warning",
                        location=f"'{user['User']}'@'{user['Host']}'",
                        description=f"sha256_password ì¸ì¦ ì‚¬ìš© (deprecated)",
                        suggestion="ALTER USER ... IDENTIFIED WITH caching_sha2_password ê¶Œì¥"
                    ))
                elif plugin == 'authentication_fido':
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.AUTH_PLUGIN_ISSUE,
                        severity="error",
                        location=f"'{user['User']}'@'{user['Host']}'",
                        description=f"authentication_fido í”ŒëŸ¬ê·¸ì¸ ì‚¬ìš© (8.4ì—ì„œ ì œê±°ë¨)",
                        suggestion="authentication_webauthn ë˜ëŠ” ë‹¤ë¥¸ ì¸ì¦ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ í•„ìš”"
                    ))

            if issues:
                self._log(f"  âš ï¸ ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ì´ìŠˆ {len(issues)}ê°œ ë°œê²¬")
            else:
                self._log("  âœ… ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ì •ìƒ")

        except Exception as e:
            self._log(f"  âš ï¸ ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

        return issues

    def check_zerofill_columns(self, schema: str) -> List[CompatibilityIssue]:
        """ZEROFILL ì†ì„± ì‚¬ìš© ì»¬ëŸ¼ í™•ì¸"""
        self._log("ğŸ” ZEROFILL ì†ì„± í™•ì¸ ì¤‘...")

        issues = []

        query = """
        SELECT TABLE_NAME, COLUMN_NAME, COLUMN_TYPE
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
            AND COLUMN_TYPE LIKE '%%ZEROFILL%%'
        """
        columns = self.connector.execute(query, (schema,))

        for col in columns:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.ZEROFILL_USAGE,
                severity="warning",
                location=f"{schema}.{col['TABLE_NAME']}.{col['COLUMN_NAME']}",
                description=f"ZEROFILL ì†ì„± ì‚¬ìš©: {col['COLUMN_TYPE']}",
                suggestion="ZEROFILLì€ deprecatedë¨, ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ LPAD() ë“±ìœ¼ë¡œ ì²˜ë¦¬ ê¶Œì¥"
            ))

        if issues:
            self._log(f"  âš ï¸ ZEROFILL ì‚¬ìš© {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… ZEROFILL ì‚¬ìš© ì—†ìŒ")

        return issues

    def check_float_precision(self, schema: str) -> List[CompatibilityIssue]:
        """FLOAT(M,D), DOUBLE(M,D) êµ¬ë¬¸ í™•ì¸"""
        self._log("ğŸ” FLOAT/DOUBLE ì •ë°€ë„ êµ¬ë¬¸ í™•ì¸ ì¤‘...")

        issues = []

        # FLOAT(M,D), DOUBLE(M,D) í˜•íƒœ í™•ì¸
        query = """
        SELECT TABLE_NAME, COLUMN_NAME, COLUMN_TYPE, DATA_TYPE
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
            AND DATA_TYPE IN ('float', 'double')
            AND COLUMN_TYPE REGEXP '^(float|double)\\\\([0-9]+,[0-9]+\\\\)'
        """
        columns = self.connector.execute(query, (schema,))

        for col in columns:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.FLOAT_PRECISION,
                severity="warning",
                location=f"{schema}.{col['TABLE_NAME']}.{col['COLUMN_NAME']}",
                description=f"FLOAT/DOUBLE ì •ë°€ë„ êµ¬ë¬¸ ì‚¬ìš©: {col['COLUMN_TYPE']}",
                suggestion="FLOAT(M,D) êµ¬ë¬¸ì€ deprecatedë¨, FLOAT ë˜ëŠ” DECIMAL(M,D) ì‚¬ìš© ê¶Œì¥"
            ))

        if issues:
            self._log(f"  âš ï¸ FLOAT/DOUBLE ì •ë°€ë„ êµ¬ë¬¸ {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… FLOAT/DOUBLE êµ¬ë¬¸ ì •ìƒ")

        return issues

    def check_fk_name_length(self, schema: str) -> List[CompatibilityIssue]:
        """FK ì´ë¦„ 64ì ì´ˆê³¼ í™•ì¸"""
        self._log("ğŸ” FK ì´ë¦„ ê¸¸ì´ í™•ì¸ ì¤‘...")

        issues = []

        query = """
        SELECT CONSTRAINT_NAME, TABLE_NAME
        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS
        WHERE TABLE_SCHEMA = %s
            AND CONSTRAINT_TYPE = 'FOREIGN KEY'
            AND LENGTH(CONSTRAINT_NAME) > 64
        """
        fks = self.connector.execute(query, (schema,))

        for fk in fks:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.FK_NAME_LENGTH,
                severity="error",
                location=f"{schema}.{fk['TABLE_NAME']}.{fk['CONSTRAINT_NAME']}",
                description=f"FK ì´ë¦„ì´ 64ì ì´ˆê³¼: {len(fk['CONSTRAINT_NAME'])}ì",
                suggestion="FK ì´ë¦„ì„ 64ì ì´í•˜ë¡œ ë³€ê²½ í•„ìš” (8.4 ì œí•œ)"
            ))

        if issues:
            self._log(f"  âš ï¸ FK ì´ë¦„ ê¸¸ì´ ì´ˆê³¼ {len(issues)}ê°œ ë°œê²¬")
        else:
            self._log("  âœ… FK ì´ë¦„ ê¸¸ì´ ì •ìƒ")

        return issues

    def check_int_display_width(self, schema: str) -> List[CompatibilityIssue]:
        """INT(11) ë“± í‘œì‹œ ë„ˆë¹„ ì‚¬ìš© í™•ì¸ (TINYINT(1) ì œì™¸)"""
        self._log("ğŸ” INT í‘œì‹œ ë„ˆë¹„ í™•ì¸ ì¤‘...")

        issues = []

        query = """
        SELECT TABLE_NAME, COLUMN_NAME, COLUMN_TYPE
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
            AND DATA_TYPE IN ('tinyint', 'smallint', 'mediumint', 'int', 'bigint')
            AND COLUMN_TYPE REGEXP '^(tinyint|smallint|mediumint|int|bigint)\\\\([0-9]+\\\\)'
            AND NOT (DATA_TYPE = 'tinyint' AND COLUMN_TYPE LIKE 'tinyint(1)%%')
        """
        columns = self.connector.execute(query, (schema,))

        for col in columns:
            issues.append(CompatibilityIssue(
                issue_type=IssueType.INT_DISPLAY_WIDTH,
                severity="info",
                location=f"{schema}.{col['TABLE_NAME']}.{col['COLUMN_NAME']}",
                description=f"INT í‘œì‹œ ë„ˆë¹„ ì‚¬ìš©: {col['COLUMN_TYPE']}",
                suggestion="í‘œì‹œ ë„ˆë¹„ëŠ” deprecatedë¨, 8.4ì—ì„œ ìë™ ë¬´ì‹œë¨ (ì˜í–¥ ìµœì†Œ)"
            ))

        if issues:
            self._log(f"  â„¹ï¸ INT í‘œì‹œ ë„ˆë¹„ {len(issues)}ê°œ ë°œê²¬ (ê²½ë¯¸)")
        else:
            self._log("  âœ… INT í‘œì‹œ ë„ˆë¹„ ì—†ìŒ")

        return issues

    def get_fk_visualization(self, schema: str) -> str:
        """FK ê´€ê³„ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì‹œê°í™”"""
        fk_tree = self.build_fk_tree(schema)

        if not fk_tree:
            return "FK ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤."

        lines = ["FK ê´€ê³„ íŠ¸ë¦¬:", ""]

        # ë£¨íŠ¸ í…Œì´ë¸” ì°¾ê¸° (ë‹¤ë¥¸ í…Œì´ë¸”ì˜ ìì‹ì´ ì•„ë‹Œ í…Œì´ë¸”)
        all_children = set()
        for children in fk_tree.values():
            all_children.update(children)

        root_tables = set(fk_tree.keys()) - all_children

        def print_tree(table: str, prefix: str = "", is_last: bool = True):
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            lines.append(f"{prefix}{connector}{table}")

            if table in fk_tree:
                children = fk_tree[table]
                child_prefix = prefix + ("    " if is_last else "â”‚   ")
                for i, child in enumerate(children):
                    print_tree(child, child_prefix, i == len(children) - 1)

        for i, root in enumerate(sorted(root_tables)):
            print_tree(root, "", i == len(root_tables) - 1)

        return "\n".join(lines)


# ============================================================
# ë¤í”„ íŒŒì¼ ë¶„ì„ê¸° (Task 3)
# ============================================================

@dataclass
class DumpAnalysisResult:
    """ë¤í”„ íŒŒì¼ ë¶„ì„ ê²°ê³¼"""
    dump_path: str
    analyzed_at: str
    total_sql_files: int
    total_tsv_files: int
    compatibility_issues: List[CompatibilityIssue] = field(default_factory=list)


class DumpFileAnalyzer:
    """
    mysqlsh ë¤í”„ íŒŒì¼ ë¶„ì„ê¸°

    ë¤í”„ í´ë”ì˜ SQL/TSV íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ MySQL 8.4 í˜¸í™˜ì„± ì´ìŠˆë¥¼ íƒì§€í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self._progress_callback: Optional[Callable[[str], None]] = None
        self._issue_callback: Optional[Callable[[CompatibilityIssue], None]] = None

    def set_progress_callback(self, callback: Callable[[str], None]):
        """ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì •"""
        self._progress_callback = callback

    def set_issue_callback(self, callback: Callable[[CompatibilityIssue], None]):
        """ì´ìŠˆ ë°œê²¬ ì‹œ ì½œë°± ì„¤ì •"""
        self._issue_callback = callback

    def _log(self, message: str):
        """ì§„í–‰ ìƒí™© ë¡œê¹…"""
        if self._progress_callback:
            self._progress_callback(message)

    def _report_issue(self, issue: CompatibilityIssue):
        """ì´ìŠˆ ë°œê²¬ ì‹œ ì½œë°± í˜¸ì¶œ"""
        if self._issue_callback:
            self._issue_callback(issue)

    def analyze_dump_folder(self, dump_path: str) -> DumpAnalysisResult:
        """
        ë¤í”„ í´ë” ì „ì²´ ë¶„ì„

        Args:
            dump_path: mysqlsh ë¤í”„ í´ë” ê²½ë¡œ

        Returns:
            DumpAnalysisResult
        """
        from datetime import datetime

        path = Path(dump_path)
        if not path.exists():
            raise FileNotFoundError(f"ë¤í”„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dump_path}")

        self._log(f"ğŸ” ë¤í”„ í´ë” ë¶„ì„ ì‹œì‘: {dump_path}")

        issues: List[CompatibilityIssue] = []

        # SQL íŒŒì¼ ëª©ë¡
        sql_files = list(path.glob("*.sql"))
        tsv_files = list(path.glob("*.tsv")) + list(path.glob("*.tsv.zst"))

        self._log(f"  SQL íŒŒì¼: {len(sql_files)}ê°œ, ë°ì´í„° íŒŒì¼: {len(tsv_files)}ê°œ")

        # SQL íŒŒì¼ ë¶„ì„
        for i, sql_file in enumerate(sql_files, 1):
            self._log(f"  [{i}/{len(sql_files)}] {sql_file.name} ë¶„ì„ ì¤‘...")
            file_issues = self._analyze_sql_file(sql_file)
            issues.extend(file_issues)

            # ì‹¤ì‹œê°„ ì´ìŠˆ ì½œë°±
            for issue in file_issues:
                self._report_issue(issue)

        # TSV ë°ì´í„° íŒŒì¼ ë¶„ì„ (0000-00-00 ë‚ ì§œ ë“±)
        # ì••ì¶•ë˜ì§€ ì•Šì€ TSV íŒŒì¼ë§Œ ë¶„ì„ (ì••ì¶• íŒŒì¼ì€ ë„ˆë¬´ ëŠë¦¼)
        uncompressed_tsv = [f for f in tsv_files if not str(f).endswith('.zst')]
        if uncompressed_tsv:
            for i, tsv_file in enumerate(uncompressed_tsv, 1):
                self._log(f"  [{i}/{len(uncompressed_tsv)}] {tsv_file.name} ë¶„ì„ ì¤‘...")
                file_issues = self._analyze_tsv_file(tsv_file)
                issues.extend(file_issues)

                for issue in file_issues:
                    self._report_issue(issue)

        # ê²°ê³¼ ìƒì„±
        result = DumpAnalysisResult(
            dump_path=str(dump_path),
            analyzed_at=datetime.now().isoformat(),
            total_sql_files=len(sql_files),
            total_tsv_files=len(tsv_files),
            compatibility_issues=issues
        )

        # ìš”ì•½
        error_count = sum(1 for i in issues if i.severity == "error")
        warning_count = sum(1 for i in issues if i.severity == "warning")

        self._log(f"âœ… ë¤í”„ ë¶„ì„ ì™„ë£Œ")
        self._log(f"  - ì˜¤ë¥˜: {error_count}ê°œ")
        self._log(f"  - ê²½ê³ : {warning_count}ê°œ")

        return result

    def _analyze_sql_file(self, file_path: Path) -> List[CompatibilityIssue]:
        """
        SQL íŒŒì¼ ë¶„ì„ - ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ê²€ì‚¬

        Args:
            file_path: SQL íŒŒì¼ ê²½ë¡œ

        Returns:
            ë°œê²¬ëœ ì´ìŠˆ ëª©ë¡
        """
        issues = []

        try:
            content = file_path.read_text(encoding='utf-8', errors='replace')

            # 1. ZEROFILL ì†ì„± ê²€ì‚¬
            for match in ZEROFILL_PATTERN.finditer(content):
                # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸”/ì»¬ëŸ¼ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                line_start = content.rfind('\n', 0, match.start()) + 1
                line_end = content.find('\n', match.end())
                line = content[line_start:line_end]

                issues.append(CompatibilityIssue(
                    issue_type=IssueType.ZEROFILL_USAGE,
                    severity="warning",
                    location=f"{file_path.name}",
                    description=f"ZEROFILL ì†ì„± ì‚¬ìš©: {line.strip()[:80]}...",
                    suggestion="ZEROFILLì€ deprecatedë¨"
                ))

            # 2. FLOAT(M,D), DOUBLE(M,D) êµ¬ë¬¸ ê²€ì‚¬
            for match in FLOAT_PRECISION_PATTERN.finditer(content):
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.FLOAT_PRECISION,
                    severity="warning",
                    location=f"{file_path.name}",
                    description=f"FLOAT/DOUBLE ì •ë°€ë„ êµ¬ë¬¸: {match.group(0)}",
                    suggestion="FLOAT(M,D) êµ¬ë¬¸ì€ deprecatedë¨"
                ))

            # 3. FK ì´ë¦„ 64ì ì´ˆê³¼ ê²€ì‚¬
            for match in FK_NAME_LENGTH_PATTERN.finditer(content):
                fk_name = match.group(1)
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.FK_NAME_LENGTH,
                    severity="error",
                    location=f"{file_path.name}",
                    description=f"FK ì´ë¦„ 64ì ì´ˆê³¼: {fk_name[:30]}... ({len(fk_name)}ì)",
                    suggestion="FK ì´ë¦„ì„ 64ì ì´í•˜ë¡œ ë³€ê²½ í•„ìš”"
                ))

            # 4. ì¸ì¦ í”ŒëŸ¬ê·¸ì¸ ê²€ì‚¬
            for match in AUTH_PLUGIN_PATTERN.finditer(content):
                plugin = match.group(1).lower()
                severity = "error" if plugin == "mysql_native_password" else "warning"
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.AUTH_PLUGIN_ISSUE,
                    severity=severity,
                    location=f"{file_path.name}",
                    description=f"ì¸ì¦ í”ŒëŸ¬ê·¸ì¸: {plugin}",
                    suggestion="caching_sha2_password ì‚¬ìš© ê¶Œì¥"
                ))

            # 5. FTS_ í…Œì´ë¸”ëª… ê²€ì‚¬
            for match in FTS_TABLE_PREFIX_PATTERN.finditer(content):
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.FTS_TABLE_PREFIX,
                    severity="error",
                    location=f"{file_path.name}",
                    description="FTS_ ì ‘ë‘ì‚¬ í…Œì´ë¸”ëª… (ë‚´ë¶€ ì˜ˆì•½ì–´)",
                    suggestion="FTS_ ì ‘ë‘ì‚¬ëŠ” ë‚´ë¶€ ì „ë¬¸ ê²€ìƒ‰ìš©ìœ¼ë¡œ ì˜ˆì•½ë¨, í…Œì´ë¸”ëª… ë³€ê²½ í•„ìš”"
                ))

            # 6. SUPER ê¶Œí•œ ê²€ì‚¬
            for match in SUPER_PRIVILEGE_PATTERN.finditer(content):
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.SUPER_PRIVILEGE,
                    severity="warning",
                    location=f"{file_path.name}",
                    description="SUPER ê¶Œí•œ ì‚¬ìš© (deprecated)",
                    suggestion="ë™ì  ê¶Œí•œ (BINLOG_ADMIN, CONNECTION_ADMIN ë“±)ìœ¼ë¡œ ì„¸ë¶„í™” ê¶Œì¥"
                ))

            # 7. ì œê±°ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜ ì‚¬ìš© ê²€ì‚¬
            for match in SYS_VAR_USAGE_PATTERN.finditer(content):
                var_name = match.group(1)
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.REMOVED_SYS_VAR,
                    severity="error",
                    location=f"{file_path.name}",
                    description=f"ì œê±°ëœ ì‹œìŠ¤í…œ ë³€ìˆ˜ ì‚¬ìš©: {var_name}",
                    suggestion=f"'{var_name}'ì€ 8.4ì—ì„œ ì œê±°ë¨, ëŒ€ì²´ ë°©ë²• í™•ì¸ í•„ìš”"
                ))

            # 8. ì˜ˆì•½ì–´ ì¶©ëŒ (í…Œì´ë¸”/ì»¬ëŸ¼ ì´ë¦„) - CREATE TABLE ë¬¸ì—ì„œ
            table_pattern = re.compile(
                r'CREATE\s+TABLE\s+`?(\w+)`?\s*\(',
                re.IGNORECASE
            )
            column_pattern = re.compile(
                r'`(\w+)`\s+(?:INT|VARCHAR|TEXT|DATE|DECIMAL|FLOAT|DOUBLE|CHAR|BLOB|ENUM|SET)',
                re.IGNORECASE
            )

            keywords_upper = set(k.upper() for k in MigrationAnalyzer.NEW_RESERVED_KEYWORDS)

            for match in table_pattern.finditer(content):
                table_name = match.group(1)
                if table_name.upper() in keywords_upper:
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.RESERVED_KEYWORD,
                        severity="error",
                        location=f"{file_path.name}",
                        description=f"í…Œì´ë¸”ëª… '{table_name}'ì´ ì˜ˆì•½ì–´ì™€ ì¶©ëŒ",
                        suggestion="í…Œì´ë¸”ëª… ë³€ê²½ ë˜ëŠ” ë°±í‹±(`) ì‚¬ìš© í•„ìš”"
                    ))

            for match in column_pattern.finditer(content):
                column_name = match.group(1)
                if column_name.upper() in keywords_upper:
                    issues.append(CompatibilityIssue(
                        issue_type=IssueType.RESERVED_KEYWORD,
                        severity="warning",
                        location=f"{file_path.name}",
                        description=f"ì»¬ëŸ¼ëª… '{column_name}'ì´ ì˜ˆì•½ì–´ì™€ ì¶©ëŒ",
                        suggestion="ì»¬ëŸ¼ ì°¸ì¡° ì‹œ ë°±í‹±(`) ì‚¬ìš© í•„ìš”"
                    ))

        except Exception as e:
            self._log(f"  âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path.name} - {str(e)}")

        return issues

    def _analyze_tsv_file(self, file_path: Path) -> List[CompatibilityIssue]:
        """
        TSV ë°ì´í„° íŒŒì¼ ë¶„ì„ - ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬

        Args:
            file_path: TSV íŒŒì¼ ê²½ë¡œ

        Returns:
            ë°œê²¬ëœ ì´ìŠˆ ëª©ë¡
        """
        issues = []
        invalid_date_count = 0

        try:
            # ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ìƒ˜í”Œë§
            max_lines = 10000
            line_count = 0

            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                for line in f:
                    line_count += 1
                    if line_count > max_lines:
                        break

                    # 0000-00-00 ë‚ ì§œ ê²€ì‚¬
                    if INVALID_DATE_PATTERN.search(line) or INVALID_DATETIME_PATTERN.search(line):
                        invalid_date_count += 1

            if invalid_date_count > 0:
                issues.append(CompatibilityIssue(
                    issue_type=IssueType.INVALID_DATE,
                    severity="error",
                    location=f"{file_path.name}",
                    description=f"ì˜ëª»ëœ ë‚ ì§œ ê°’ ë°œê²¬: {invalid_date_count}ê°œ í–‰ (0000-00-00)",
                    suggestion="NO_ZERO_DATE SQL ëª¨ë“œ í™œì„±í™” ì‹œ ì˜¤ë¥˜ ë°œìƒ, ìœ íš¨í•œ ë‚ ì§œë¡œ ë³€í™˜ í•„ìš”"
                ))

        except Exception as e:
            self._log(f"  âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path.name} - {str(e)}")

        return issues

    def quick_scan(self, dump_path: str) -> Tuple[int, int, int]:
        """
        ë¹ ë¥¸ ìŠ¤ìº” - ì´ìŠˆ ê°œìˆ˜ë§Œ ë°˜í™˜

        Args:
            dump_path: ë¤í”„ í´ë” ê²½ë¡œ

        Returns:
            (ì˜¤ë¥˜ ìˆ˜, ê²½ê³  ìˆ˜, ì •ë³´ ìˆ˜)
        """
        try:
            result = self.analyze_dump_folder(dump_path)
            error_count = sum(1 for i in result.compatibility_issues if i.severity == "error")
            warning_count = sum(1 for i in result.compatibility_issues if i.severity == "warning")
            info_count = sum(1 for i in result.compatibility_issues if i.severity == "info")
            return error_count, warning_count, info_count
        except Exception:
            return 0, 0, 0
