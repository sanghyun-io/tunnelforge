"""
ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™ ìˆ˜ì • ìœ„ì €ë“œ Core ë¡œì§

MySQL 8.0 â†’ 8.4 ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ ê²€ì¶œëœ í˜¸í™˜ì„± ì´ìŠˆë¥¼ ìë™ ìˆ˜ì •í•˜ëŠ” í•µì‹¬ ë¡œì§.
- SmartFixGenerator: ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ Fix ì˜µì…˜ ìƒì„±
- CollationFKGraphBuilder: FK ê´€ê³„ ê·¸ë˜í”„ ë¶„ì„ (collation ì¼ê´„ ë³€ê²½ìš©)
- BatchFixExecutor: íŠ¸ëœì­ì…˜ ê¸°ë°˜ ì¼ê´„ ì‹¤í–‰
"""

from contextlib import contextmanager
from enum import Enum
from dataclasses import dataclass, field
from typing import List, Dict, Set, Optional, Tuple, Callable, Any
from collections import deque

from src.core.db_connector import MySQLConnector
from src.core.migration_constants import IssueType


class FixStrategy(Enum):
    """ìˆ˜ì • ì „ëµ"""
    # ë‚ ì§œ ê´€ë ¨
    DATE_TO_NULL = "date_to_null"                    # NULLë¡œ ë³€ê²½
    DATE_TO_MIN = "date_to_min"                      # ìµœì†Œê°’ (1970-01-01)ìœ¼ë¡œ ë³€ê²½
    DATE_TO_CUSTOM = "date_to_custom"                # ì‚¬ìš©ì ì§€ì • ë‚ ì§œ

    # Collation ê´€ë ¨
    COLLATION_SINGLE = "collation_single"            # ë‹¨ì¼ í…Œì´ë¸”ë§Œ ë³€ê²½
    COLLATION_FK_CASCADE = "collation_fk_cascade"    # FK ì—°ê´€ í…Œì´ë¸” ì¼ê´„ ë³€ê²½
    COLLATION_FK_SAFE = "collation_fk_safe"          # FK ì•ˆì „ ë³€ê²½ (DROP â†’ ë³€ê²½ â†’ ì¬ìƒì„±)

    # ê¸°íƒ€
    SKIP = "skip"                                     # ê±´ë„ˆë›°ê¸°
    MANUAL = "manual"                                 # ìˆ˜ë™ ì²˜ë¦¬


@dataclass
class FKDefinition:
    """FK ì •ì˜ (DROP/ADDìš©)

    ë³µí•© FKë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ columnsì™€ ref_columnsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    constraint_name: str
    table_name: str
    columns: List[str]          # ë³µí•© FK ì§€ì›
    ref_table: str
    ref_columns: List[str]
    on_delete: str = "RESTRICT"
    on_update: str = "RESTRICT"

    def get_drop_sql(self, schema: str) -> str:
        """FK DROP SQL ìƒì„±"""
        return f"ALTER TABLE `{schema}`.`{self.table_name}` DROP FOREIGN KEY `{self.constraint_name}`;"

    def get_add_sql(self, schema: str) -> str:
        """FK ADD SQL ìƒì„±"""
        cols = ", ".join(f"`{c}`" for c in self.columns)
        ref_cols = ", ".join(f"`{c}`" for c in self.ref_columns)
        return (
            f"ALTER TABLE `{schema}`.`{self.table_name}` ADD CONSTRAINT `{self.constraint_name}` "
            f"FOREIGN KEY ({cols}) REFERENCES `{self.ref_table}` ({ref_cols}) "
            f"ON DELETE {self.on_delete} ON UPDATE {self.on_update};"
        )


@dataclass
class FixOption:
    """ìˆ˜ì • ì˜µì…˜"""
    strategy: FixStrategy
    label: str
    description: str
    sql_template: Optional[str] = None
    requires_input: bool = False                     # ì‚¬ìš©ì ì…ë ¥ í•„ìš” ì—¬ë¶€
    input_label: Optional[str] = None                # ì…ë ¥ í•„ë“œ ë¼ë²¨
    input_default: Optional[str] = None              # ê¸°ë³¸ê°’
    is_recommended: bool = False                     # ê¶Œì¥ ì˜µì…˜ ì—¬ë¶€
    related_tables: List[str] = field(default_factory=list)  # ê´€ë ¨ í…Œì´ë¸” (collationìš©)
    modify_clause: Optional[str] = None              # column-level MODIFY COLUMN ì ˆ (ë³‘í•© ìµœì í™”ìš©)


@dataclass
class FixWizardStep:
    """ìœ„ì €ë“œ ë‹¨ê³„"""
    issue_index: int                                 # ì›ë³¸ ì´ìŠˆ ì¸ë±ìŠ¤
    issue_type: IssueType
    location: str
    description: str
    options: List[FixOption]
    selected_option: Optional[FixOption] = None
    user_input: Optional[str] = None                 # ì‚¬ìš©ì ì…ë ¥ê°’

    # FK ì—°ê´€ í…Œì´ë¸” ì¼ê´„ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìë™ í¬í•¨ ì •ë³´
    # (ì˜µì…˜ ì„ íƒ ë‹¨ê³„ë§Œ ìƒëµ, ì‹¤ì œ SQLì—ëŠ” í¬í•¨ë¨)
    included_by: Optional[str] = None                # í¬í•¨ì‹œí‚¨ ì›ë³¸ í…Œì´ë¸”ëª… (ì˜ˆ: "companies")
    included_reason: str = ""                        # í¬í•¨ ì‚¬ìœ  ì„¤ëª…


@dataclass
class FixExecutionResult:
    """ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    message: str
    sql_executed: str
    affected_rows: int = 0
    error: Optional[str] = None
    location: str = ""        # step.locationì„ í•¨ê»˜ ì €ì¥ (FK ì •ë ¬ í›„ ë§¤í•‘ ì˜¤ë¥˜ ë°©ì§€)
    description: str = ""     # ìŠ¤í‚µ/ìˆ˜ë™ì²˜ë¦¬ ì‚¬ìœ  (step.description ë˜ëŠ” ì„ íƒëœ ì˜µì…˜ description)


@dataclass
class BatchExecutionResult:
    """ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼"""
    total_steps: int
    success_count: int
    fail_count: int
    skip_count: int
    results: List[FixExecutionResult]
    total_affected_rows: int = 0
    rollback_sql: str = ""  # Rollback SQL


class SmartFixGenerator:
    """ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ Fix ì˜µì…˜ ìƒì„±ê¸°

    í˜¸í™˜ì„± ì´ìŠˆì— ëŒ€í•´ ì ì ˆí•œ ìˆ˜ì • ì˜µì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ë‚ ì§œ ì´ìŠˆ: nullable ì—¬ë¶€ í™•ì¸ í›„ ì˜µì…˜ ì œì‹œ
    - Collation ì´ìŠˆ: FK ì—°ê´€ í…Œì´ë¸” í¬í•¨ ì˜µì…˜ ì œì‹œ
    """

    def __init__(self, connector: MySQLConnector, schema: str):
        self.connector = connector
        self.schema = schema
        self._column_nullable_cache: Dict[str, bool] = {}
        self._fk_graph_builder: Optional['CollationFKGraphBuilder'] = None

    def get_fk_graph_builder(self) -> 'CollationFKGraphBuilder':
        """FK ê·¸ë˜í”„ ë¹Œë” (lazy init)"""
        if self._fk_graph_builder is None:
            self._fk_graph_builder = CollationFKGraphBuilder(self.connector, self.schema)
            self._fk_graph_builder.build_graph()
        return self._fk_graph_builder

    def get_fix_options(self, issue: Any) -> List[FixOption]:
        """ì´ìŠˆì— ëŒ€í•œ ìˆ˜ì • ì˜µì…˜ ìƒì„±

        Args:
            issue: CompatibilityIssue ê°ì²´

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•œ FixOption ëª©ë¡
        """
        handlers = {
            IssueType.INVALID_DATE: self._get_invalid_date_options,
            IssueType.CHARSET_ISSUE: self._get_charset_options,
            IssueType.ZEROFILL_USAGE: self._get_zerofill_options,
            IssueType.FLOAT_PRECISION: self._get_float_precision_options,
            IssueType.INT_DISPLAY_WIDTH: self._get_int_display_width_options,
            IssueType.ENUM_EMPTY_VALUE: self._get_enum_empty_options,
            IssueType.DEPRECATED_ENGINE: self._get_deprecated_engine_options,
        }

        handler = handlers.get(issue.issue_type)
        if handler:
            options = handler(issue)
        else:
            # ê¸°ë³¸ ì˜µì…˜ (ìˆ˜ë™ ì²˜ë¦¬ ë˜ëŠ” ê±´ë„ˆë›°ê¸°)
            options = self._get_default_options(issue)

        # í•­ìƒ "ê±´ë„ˆë›°ê¸°" ì˜µì…˜ ì¶”ê°€
        options.append(FixOption(
            strategy=FixStrategy.SKIP,
            label="ê±´ë„ˆë›°ê¸°",
            description="ì´ ì´ìŠˆëŠ” ìˆ˜ì •í•˜ì§€ ì•Šê³  ë„˜ì–´ê°‘ë‹ˆë‹¤."
        ))

        return options

    def _is_column_nullable(self, table: str, column: str) -> bool:
        """ì»¬ëŸ¼ì˜ nullable ì—¬ë¶€ í™•ì¸"""
        cache_key = f"{self.schema}.{table}.{column}"
        if cache_key in self._column_nullable_cache:
            return self._column_nullable_cache[cache_key]

        query = """
        SELECT IS_NULLABLE
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s AND COLUMN_NAME = %s
        """
        result = self.connector.execute(query, (self.schema, table, column))

        is_nullable = result[0]['IS_NULLABLE'] == 'YES' if result else False
        self._column_nullable_cache[cache_key] = is_nullable
        return is_nullable

    def _get_column_definition(
        self,
        schema: str,
        table: str,
        column: str,
        charset: Optional[str] = None,
        collation: Optional[str] = None
    ) -> Optional[str]:
        """ì»¬ëŸ¼ì˜ ì „ì²´ ì •ì˜ ì¡°íšŒ (MODIFY COLUMNìš©)

        Args:
            charset:   ì‚½ì…í•  CHARACTER SET ê°’ (ì˜ˆ: 'utf8mb4'). Noneì´ë©´ ìƒëµ.
            collation: ì‚½ì…í•  COLLATE ê°’ (ì˜ˆ: 'utf8mb4_unicode_ci'). Noneì´ë©´ ìƒëµ.

        Returns:
            ì»¬ëŸ¼ ì •ì˜ ë¬¸ìì—´. charset ì§€ì • ì‹œ ì˜¬ë°”ë¥¸ MySQL ìˆœì„œë¡œ ì¡°ë¦½:
            "COLUMN_TYPE [CHARACTER SET ...] [COLLATE ...] [NOT NULL] [DEFAULT ...] [EXTRA]"
            ì¡°íšŒ ì‹¤íŒ¨ ì‹œ None

        Note:
            MySQLì—ì„œ CHARACTER SET / COLLATE ì ˆì€ ë°ì´í„° íƒ€ì…ì˜ ì¼ë¶€ì´ë¯€ë¡œ
            ë°˜ë“œì‹œ NOT NULL / DEFAULT ì•ì— ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
            (NOT NULL ë’¤ì— CHARACTER SETì„ ë‘ë©´ 1064 ë¬¸ë²• ì˜¤ë¥˜ ë°œìƒ)
        """
        query = """
        SELECT
            COLUMN_TYPE,
            IS_NULLABLE,
            COLUMN_DEFAULT,
            EXTRA
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s AND COLUMN_NAME = %s
        """
        result = self.connector.execute(query, (schema, table, column))

        if not result:
            return None

        col = result[0]
        parts = [col['COLUMN_TYPE']]  # VARCHAR(255), TEXT, etc.

        # CHARACTER SET / COLLATEëŠ” NOT NULL ì•ì— ì‚½ì… (MySQL ë¬¸ë²• ìš”êµ¬ì‚¬í•­)
        if charset:
            parts.append(f"CHARACTER SET {charset}")
        if collation:
            parts.append(f"COLLATE {collation}")

        # NOT NULL / NULL
        if col['IS_NULLABLE'] == 'NO':
            parts.append('NOT NULL')

        # DEFAULT
        if col['COLUMN_DEFAULT'] is not None:
            default_val = col['COLUMN_DEFAULT']
            # ë¬¸ìì—´ì´ë©´ ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
            if isinstance(default_val, str) and not default_val.startswith('CURRENT_'):
                parts.append(f"DEFAULT '{default_val}'")
            else:
                parts.append(f"DEFAULT {default_val}")

        # EXTRA (AUTO_INCREMENT, ON UPDATE CURRENT_TIMESTAMP ë“±)
        if col['EXTRA']:
            parts.append(col['EXTRA'])

        return ' '.join(parts)

    def _get_invalid_date_options(self, issue: Any) -> List[FixOption]:
        """0000-00-00 ë‚ ì§œ ìˆ˜ì • ì˜µì…˜"""
        options = []
        table = issue.table_name
        column = issue.column_name

        if not table or not column:
            return self._get_default_options(issue)

        # nullable ì—¬ë¶€ í™•ì¸
        is_nullable = self._is_column_nullable(table, column)

        # 1. NULLë¡œ ë³€ê²½ (nullable ì»¬ëŸ¼ë§Œ)
        if is_nullable:
            options.append(FixOption(
                strategy=FixStrategy.DATE_TO_NULL,
                label="NULLë¡œ ë³€ê²½ (ê¶Œì¥)",
                description=f"0000-00-00 ê°’ì„ NULLë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
                sql_template=f"""UPDATE `{self.schema}`.`{table}`
SET `{column}` = NULL
WHERE `{column}` = '0000-00-00'
   OR `{column}` = '0000-00-00 00:00:00'
   OR (MONTH(`{column}`) = 0 OR DAY(`{column}`) = 0);""",
                is_recommended=True
            ))

        # 2. ìµœì†Œê°’ìœ¼ë¡œ ë³€ê²½
        options.append(FixOption(
            strategy=FixStrategy.DATE_TO_MIN,
            label="1970-01-01ë¡œ ë³€ê²½",
            description="0000-00-00 ê°’ì„ Unix ì‹œì‘ì¼(1970-01-01)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
            sql_template=f"""UPDATE `{self.schema}`.`{table}`
SET `{column}` = '1970-01-01'
WHERE `{column}` = '0000-00-00'
   OR `{column}` = '0000-00-00 00:00:00'
   OR (MONTH(`{column}`) = 0 OR DAY(`{column}`) = 0);""",
            is_recommended=not is_nullable  # nullable ì•„ë‹ˆë©´ ì´ê²Œ ê¶Œì¥
        ))

        # 3. ì‚¬ìš©ì ì§€ì • ë‚ ì§œ
        options.append(FixOption(
            strategy=FixStrategy.DATE_TO_CUSTOM,
            label="ì‚¬ìš©ì ì§€ì • ë‚ ì§œ",
            description="ì›í•˜ëŠ” ë‚ ì§œë¡œ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.",
            sql_template=f"""UPDATE `{self.schema}`.`{table}`
SET `{column}` = '{{custom_date}}'
WHERE `{column}` = '0000-00-00'
   OR `{column}` = '0000-00-00 00:00:00'
   OR (MONTH(`{column}`) = 0 OR DAY(`{column}`) = 0);""",
            requires_input=True,
            input_label="ë³€ê²½í•  ë‚ ì§œ (YYYY-MM-DD)",
            input_default="2000-01-01"
        ))

        return options

    def _get_charset_options(self, issue: Any) -> List[FixOption]:
        """Collation/Charset ìˆ˜ì • ì˜µì…˜"""
        options = []
        location_parts = issue.location.split('.')

        if len(location_parts) < 2:
            return self._get_default_options(issue)

        schema = location_parts[0]
        table = location_parts[1]
        column = location_parts[2] if len(location_parts) > 2 else None

        if column:
            # ì»¬ëŸ¼ ë ˆë²¨ charset ë³€ê²½ - CHARACTER SETì„ NOT NULL ì•ì— ì‚½ì…í•˜ì—¬ ì¡°íšŒ
            col_def = self._get_column_definition(
                schema, table, column,
                charset='utf8mb4',
                collation='utf8mb4_unicode_ci'
            )

            if col_def:
                # ì»¬ëŸ¼ ì •ì˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí•œ ê²½ìš°
                # col_defì— ì´ë¯¸ CHARACTER SET / COLLATEê°€ ì˜¬ë°”ë¥¸ ìœ„ì¹˜(NOT NULL ì•)ì— í¬í•¨ë¨
                modify_clause = f"`{column}` {col_def}"
                options.append(FixOption(
                    strategy=FixStrategy.COLLATION_SINGLE,
                    label="ì´ ì»¬ëŸ¼ë§Œ ë³€ê²½",
                    description=f"{table}.{column} ì»¬ëŸ¼ì˜ charsetì„ utf8mb4ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
                    sql_template=f"ALTER TABLE `{schema}`.`{table}` MODIFY COLUMN `{column}` {col_def};",
                    modify_clause=modify_clause,  # ë³‘í•© ìµœì í™”: regex íŒŒì‹± ë¶ˆí•„ìš”
                ))
            else:
                # ì»¬ëŸ¼ ì •ì˜ ì¡°íšŒ ì‹¤íŒ¨ - ìˆ˜ë™ ì²˜ë¦¬ë¡œ ì•ˆë‚´
                options.append(FixOption(
                    strategy=FixStrategy.MANUAL,
                    label="ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”",
                    description=f"{table}.{column} ì»¬ëŸ¼ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í›„ ë³€ê²½í•˜ì„¸ìš”.",
                    sql_template=f"-- {table}.{column} ì»¬ëŸ¼ íƒ€ì… í™•ì¸ í›„ ìˆ˜ë™ ë³€ê²½ í•„ìš”\n"
                                 f"-- SHOW CREATE TABLE `{schema}`.`{table}`;",
                ))
        else:
            # í…Œì´ë¸” ë ˆë²¨ charset ë³€ê²½

            # 1. ë‹¨ì¼ í…Œì´ë¸”ë§Œ ë³€ê²½
            options.append(FixOption(
                strategy=FixStrategy.COLLATION_SINGLE,
                label="ì´ í…Œì´ë¸”ë§Œ ë³€ê²½",
                description=f"{table} í…Œì´ë¸”ë§Œ utf8mb4ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
                sql_template=f"ALTER TABLE `{schema}`.`{table}` CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
            ))

            # 2. FK ì—°ê´€ í…Œì´ë¸” ì¼ê´„ ë³€ê²½
            fk_builder = self.get_fk_graph_builder()
            related_tables = fk_builder.get_related_tables(table)

            if related_tables:
                # ìœ„ìƒ ì •ë ¬ ìˆœì„œë¡œ SQL ìƒì„±
                ordered_tables = fk_builder.get_topological_order(related_tables | {table})

                sql_lines = ["SET FOREIGN_KEY_CHECKS = 0;"]
                for t in ordered_tables:
                    sql_lines.append(
                        f"ALTER TABLE `{schema}`.`{t}` "
                        f"CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
                    )
                sql_lines.append("SET FOREIGN_KEY_CHECKS = 1;")

                options.append(FixOption(
                    strategy=FixStrategy.COLLATION_FK_CASCADE,
                    label=f"FK ì—°ê´€ í…Œì´ë¸” ì¼ê´„ ë³€ê²½ ({len(ordered_tables)}ê°œ)",
                    description=(
                        f"FKë¡œ ì—°ê²°ëœ í…Œì´ë¸”ì„ ëª¨ë‘ utf8mb4ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n"
                        f"ëŒ€ìƒ í…Œì´ë¸”: {', '.join(ordered_tables)}"
                    ),
                    sql_template="\n".join(sql_lines),
                    related_tables=list(ordered_tables),
                    is_recommended=False  # FK ì•ˆì „ ë³€ê²½ì´ ê¶Œì¥
                ))

                # 3. FK ì•ˆì „ ë³€ê²½ (ê¶Œì¥ - Error 3780 ë°©ì§€)
                # FKë¥¼ ì„ì‹œ DROP â†’ charset ë³€ê²½ â†’ FK ì¬ìƒì„±
                fk_safe_changer = FKSafeCharsetChanger(self.connector, schema)
                safe_sql_parts = fk_safe_changer.generate_safe_charset_sql(
                    related_tables | {table},
                    charset="utf8mb4",
                    collation="utf8mb4_unicode_ci"
                )

                options.append(FixOption(
                    strategy=FixStrategy.COLLATION_FK_SAFE,
                    label=f"FK ì•ˆì „ ë³€ê²½ ({len(ordered_tables)}ê°œ í…Œì´ë¸”, {safe_sql_parts['fk_count']}ê°œ FK)",
                    description=(
                        f"âš ï¸ Error 3780 ë°©ì§€: FKë¥¼ ì„ì‹œ DROP í›„ charset ë³€ê²½, FK ì¬ìƒì„±í•©ë‹ˆë‹¤.\n"
                        f"ëŒ€ìƒ í…Œì´ë¸”: {', '.join(ordered_tables)}\n"
                        f"ì˜í–¥ë°›ëŠ” FK: {safe_sql_parts['fk_count']}ê°œ"
                    ),
                    sql_template="\n".join(safe_sql_parts['full_sql']),
                    related_tables=list(ordered_tables),
                    is_recommended=True
                ))

        return options

    def _get_zerofill_options(self, issue: Any) -> List[FixOption]:
        """ZEROFILL ì†ì„± ì œê±° ì˜µì…˜"""
        return [
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="ìˆ˜ë™ ì²˜ë¦¬",
                description=(
                    "ZEROFILLì€ deprecatedë©ë‹ˆë‹¤. "
                    "ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ LPAD() í•¨ìˆ˜ë¡œ í¬ë§·íŒ… ì²˜ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
                    "ì˜ˆ: SELECT LPAD(column, 5, '0') FROM table;"
                ),
                sql_template="-- ZEROFILL ì œê±° í›„ LPAD() í•¨ìˆ˜ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í¬ë§·íŒ… ì²˜ë¦¬"
            )
        ]

    def _get_float_precision_options(self, issue: Any) -> List[FixOption]:
        """FLOAT(M,D) êµ¬ë¬¸ ìˆ˜ì • ì˜µì…˜"""
        table = issue.table_name
        column = issue.column_name

        if not table or not column:
            return self._get_default_options(issue)

        return [
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="FLOATë¡œ ë³€ê²½",
                description="ì •ë°€ë„ êµ¬ë¬¸ì„ ì œê±°í•˜ê³  FLOAT íƒ€ì…ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
                sql_template=f"ALTER TABLE `{self.schema}`.`{table}` MODIFY COLUMN `{column}` FLOAT;",
                is_recommended=True
            ),
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="DECIMALë¡œ ë³€ê²½",
                description="ì •í™•í•œ ì†Œìˆ˜ì  ì—°ì‚°ì´ í•„ìš”í•˜ë©´ DECIMALì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
                sql_template=f"ALTER TABLE `{self.schema}`.`{table}` MODIFY COLUMN `{column}` DECIMAL(10,2);",
                requires_input=True,
                input_label="DECIMAL ì •ë°€ë„ (M,D)",
                input_default="10,2"
            )
        ]

    def _get_int_display_width_options(self, issue: Any) -> List[FixOption]:
        """INT í‘œì‹œ ë„ˆë¹„ ìˆ˜ì • ì˜µì…˜"""
        return [
            FixOption(
                strategy=FixStrategy.SKIP,
                label="ë¬´ì‹œ (ê¶Œì¥)",
                description=(
                    "INT í‘œì‹œ ë„ˆë¹„ëŠ” MySQL 8.4ì—ì„œ ìë™ìœ¼ë¡œ ë¬´ì‹œë©ë‹ˆë‹¤.\n"
                    "ë³„ë„ ìˆ˜ì • ì—†ì´ ì‚¬ìš©í•´ë„ ì˜í–¥ì´ ì—†ìŠµë‹ˆë‹¤."
                ),
                is_recommended=True
            )
        ]

    def _get_enum_empty_options(self, issue: Any) -> List[FixOption]:
        """ENUM ë¹ˆ ë¬¸ìì—´ ìˆ˜ì • ì˜µì…˜"""
        return [
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="ìˆ˜ë™ ì²˜ë¦¬",
                description=(
                    "ENUM ì •ì˜ì—ì„œ ë¹ˆ ë¬¸ìì—´('')ì„ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.\n"
                    "ë¨¼ì € ë°ì´í„°ë¥¼ ì •ë¦¬í•œ í›„ ENUM ì •ì˜ë¥¼ ë³€ê²½í•˜ì„¸ìš”."
                ),
                sql_template="-- ENUM ì •ì˜ì—ì„œ ë¹ˆ ë¬¸ìì—´('') ì œê±° ë° ë°ì´í„° ì •ì œ í•„ìš”"
            )
        ]

    def _get_deprecated_engine_options(self, issue: Any) -> List[FixOption]:
        """deprecated ìŠ¤í† ë¦¬ì§€ ì—”ì§„ ìˆ˜ì • ì˜µì…˜"""
        table = issue.table_name
        if not table:
            parts = issue.location.split('.')
            table = parts[1] if len(parts) > 1 else None

        if not table:
            return self._get_default_options(issue)

        return [
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="InnoDBë¡œ ë³€ê²½",
                description="í…Œì´ë¸” ì—”ì§„ì„ InnoDBë¡œ ë³€ê²½í•©ë‹ˆë‹¤.",
                sql_template=f"ALTER TABLE `{self.schema}`.`{table}` ENGINE=InnoDB;",
                is_recommended=True
            )
        ]

    def _get_default_options(self, issue: Any) -> List[FixOption]:
        """ê¸°ë³¸ ì˜µì…˜ (ìˆ˜ë™ ì²˜ë¦¬)"""
        return [
            FixOption(
                strategy=FixStrategy.MANUAL,
                label="ìˆ˜ë™ ì²˜ë¦¬",
                description="ì´ ì´ìŠˆëŠ” ìë™ ìˆ˜ì •ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.",
                sql_template=f"-- ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”: {issue.description}"
            )
        ]

    def generate_sql(self, step: FixWizardStep) -> str:
        """ì„ íƒëœ ì˜µì…˜ìœ¼ë¡œ SQL ìƒì„±"""
        if not step.selected_option:
            return ""

        sql = step.selected_option.sql_template or ""

        # ì‚¬ìš©ì ì…ë ¥ê°’ ëŒ€ì²´
        if step.selected_option.requires_input and step.user_input:
            sql = sql.replace("{custom_date}", step.user_input)
            sql = sql.replace("{precision}", step.user_input)

        return sql


class CollationFKGraphBuilder:
    """FK ê´€ê³„ ê·¸ë˜í”„ ë¶„ì„ê¸°

    Collation ë³€ê²½ ì‹œ FKë¡œ ì—°ê²°ëœ í…Œì´ë¸”ì„ í•¨ê»˜ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
    ì´ í´ë˜ìŠ¤ëŠ” FK ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬:
    1. ì—°ê´€ëœ í…Œì´ë¸” ëª©ë¡ íƒìƒ‰ (BFS)
    2. ë³€ê²½ ìˆœì„œ ê²°ì • (ìœ„ìƒ ì •ë ¬)
    """

    def __init__(self, connector: MySQLConnector, schema: str):
        self.connector = connector
        self.schema = schema
        # ì–‘ë°©í–¥ ê·¸ë˜í”„: table -> set of related tables
        self.graph: Dict[str, Set[str]] = {}
        # ë°©í–¥ ê·¸ë˜í”„: child -> parent (ìœ„ìƒ ì •ë ¬ìš©)
        self.parent_graph: Dict[str, Set[str]] = {}

    def build_graph(self):
        """FK ê´€ê³„ ê·¸ë˜í”„ êµ¬ì„±

        Note: VIEWëŠ” FK ê´€ê³„ ëŒ€ìƒì—ì„œ ì œì™¸ (BASE TABLEë§Œ í¬í•¨)
        """
        query = """
        SELECT
            kcu.TABLE_NAME as CHILD_TABLE,
            kcu.REFERENCED_TABLE_NAME as PARENT_TABLE
        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu
        JOIN INFORMATION_SCHEMA.TABLES t_child
            ON kcu.TABLE_NAME = t_child.TABLE_NAME
            AND kcu.TABLE_SCHEMA = t_child.TABLE_SCHEMA
        JOIN INFORMATION_SCHEMA.TABLES t_parent
            ON kcu.REFERENCED_TABLE_NAME = t_parent.TABLE_NAME
            AND kcu.TABLE_SCHEMA = t_parent.TABLE_SCHEMA
        WHERE kcu.TABLE_SCHEMA = %s
            AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
            AND t_child.TABLE_TYPE = 'BASE TABLE'
            AND t_parent.TABLE_TYPE = 'BASE TABLE'
        """
        rows = self.connector.execute(query, (self.schema,))

        for row in rows:
            child = row['CHILD_TABLE']
            parent = row['PARENT_TABLE']

            # ì–‘ë°©í–¥ ê·¸ë˜í”„
            if child not in self.graph:
                self.graph[child] = set()
            if parent not in self.graph:
                self.graph[parent] = set()

            self.graph[child].add(parent)
            self.graph[parent].add(child)

            # ë°©í–¥ ê·¸ë˜í”„ (ìì‹ â†’ ë¶€ëª¨)
            if child not in self.parent_graph:
                self.parent_graph[child] = set()
            self.parent_graph[child].add(parent)

    def get_related_tables(self, start_table: str) -> Set[str]:
        """BFSë¡œ ì—°ê´€ í…Œì´ë¸” íƒìƒ‰

        Args:
            start_table: ì‹œì‘ í…Œì´ë¸”

        Returns:
            ì—°ê´€ëœ ëª¨ë“  í…Œì´ë¸” ì§‘í•© (ì‹œì‘ í…Œì´ë¸” ì œì™¸)
        """
        if start_table not in self.graph:
            return set()

        visited = {start_table}
        queue = deque([start_table])
        related = set()

        while queue:
            current = queue.popleft()
            for neighbor in self.graph.get(current, set()):
                if neighbor not in visited:
                    visited.add(neighbor)
                    related.add(neighbor)
                    queue.append(neighbor)

        return related

    def get_topological_order(self, tables: Set[str]) -> List[str]:
        """ìœ„ìƒ ì •ë ¬ (Kahn's algorithm)

        FK ê´€ê³„ì—ì„œ ë¶€ëª¨ í…Œì´ë¸”ì„ ë¨¼ì € ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

        Args:
            tables: ì •ë ¬í•  í…Œì´ë¸” ì§‘í•©

        Returns:
            ìœ„ìƒ ì •ë ¬ëœ í…Œì´ë¸” ëª©ë¡ (ë¶€ëª¨ ë¨¼ì €)
        """
        # ë¶€ë¶„ ê·¸ë˜í”„ì˜ ì§„ì… ì°¨ìˆ˜ ê³„ì‚°
        in_degree: Dict[str, int] = {t: 0 for t in tables}

        for child in tables:
            parents = self.parent_graph.get(child, set())
            for parent in parents:
                if parent in tables:
                    in_degree[child] += 1

        # ì§„ì… ì°¨ìˆ˜ê°€ 0ì¸ ë…¸ë“œ(ë£¨íŠ¸ í…Œì´ë¸”)ë¶€í„° ì‹œì‘
        queue = deque([t for t in tables if in_degree[t] == 0])
        result = []

        while queue:
            current = queue.popleft()
            result.append(current)

            # í˜„ì¬ ë…¸ë“œë¥¼ ë¶€ëª¨ë¡œ ê°€ì§„ ìì‹ë“¤ì˜ ì§„ì… ì°¨ìˆ˜ ê°ì†Œ
            for child in tables:
                if current in self.parent_graph.get(child, set()):
                    in_degree[child] -= 1
                    if in_degree[child] == 0:
                        queue.append(child)

        # ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìœ¼ë©´ ë‚¨ì€ í…Œì´ë¸” ì¶”ê°€
        remaining = [t for t in tables if t not in result]
        result.extend(remaining)

        return result

    def get_children(self, table: str) -> Set[str]:
        """tableì„ ì°¸ì¡°í•˜ëŠ” ìì‹ í…Œì´ë¸” ëª©ë¡

        Args:
            table: ë¶€ëª¨ í…Œì´ë¸”ëª…

        Returns:
            ìì‹ í…Œì´ë¸” ì§‘í•© (ì´ í…Œì´ë¸”ì„ FKë¡œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ë“¤)
        """
        children = set()
        for child, parents in self.parent_graph.items():
            if table in parents:
                children.add(child)
        return children

    def get_parents(self, table: str) -> Set[str]:
        """tableì´ ì°¸ì¡°í•˜ëŠ” ë¶€ëª¨ í…Œì´ë¸” ëª©ë¡

        Args:
            table: ìì‹ í…Œì´ë¸”ëª…

        Returns:
            ë¶€ëª¨ í…Œì´ë¸” ì§‘í•© (ì´ í…Œì´ë¸”ì´ FKë¡œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ë“¤)
        """
        return self.parent_graph.get(table, set()).copy()

    def get_cascade_skip_tables(self, table_to_skip: str, target_tables: Set[str]) -> Set[str]:
        """íŠ¹ì • í…Œì´ë¸” ê±´ë„ˆë›°ê¸° ì‹œ ì—°ì‡„ì ìœ¼ë¡œ ê±´ë„ˆë›°ì–´ì•¼ í•˜ëŠ” í…Œì´ë¸” ëª©ë¡

        ê·œì¹™:
        1. table_to_skipì„ ì°¸ì¡°í•˜ëŠ” ìì‹ í…Œì´ë¸” â†’ ë°˜ë“œì‹œ ê±´ë„ˆë›°ê¸°
           (ë¶€ëª¨ charsetì´ ë³€ê²½ë˜ì§€ ì•Šìœ¼ë©´ ìì‹ë„ ë³€ê²½ ë¶ˆê°€)
        2. table_to_skipì´ ì°¸ì¡°í•˜ëŠ” ë¶€ëª¨ (target_tablesì— ìˆìœ¼ë©´) â†’ ê±´ë„ˆë›°ê¸°
           (ìì‹ì´ ë³€ê²½ë˜ì§€ ì•Šìœ¼ë©´ ë¶€ëª¨ë§Œ ë³€ê²½í•´ë„ FK ë¶ˆì¼ì¹˜ ë°œìƒ)
        3. ìœ„ í…Œì´ë¸”ë“¤ì— ëŒ€í•´ ì¬ê·€ì ìœ¼ë¡œ BFS ìˆ˜í–‰

        Args:
            table_to_skip: ê±´ë„ˆë›°ê¸°í•  í…Œì´ë¸”
            target_tables: ë³€ê²½ ëŒ€ìƒ í…Œì´ë¸” ì§‘í•©

        Returns:
            ì—°ì‡„ì ìœ¼ë¡œ ê±´ë„ˆë›°ì–´ì•¼ í•˜ëŠ” í…Œì´ë¸” ì§‘í•© (table_to_skip ì œì™¸)
        """
        cascade_skip = set()
        visited = {table_to_skip}
        queue = deque([table_to_skip])

        while queue:
            current = queue.popleft()

            # 1. ìì‹ í…Œì´ë¸” (currentë¥¼ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
            children = self.get_children(current)
            for child in children:
                if child in target_tables and child not in visited:
                    visited.add(child)
                    cascade_skip.add(child)
                    queue.append(child)

            # 2. ë¶€ëª¨ í…Œì´ë¸” (currentê°€ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
            # ìì‹ì´ ê±´ë„ˆë›°ë©´ ë¶€ëª¨ë„ ê±´ë„ˆë›°ì–´ì•¼ í•¨ (FK ì¼ê´€ì„±)
            parents = self.get_parents(current)
            for parent in parents:
                if parent in target_tables and parent not in visited:
                    visited.add(parent)
                    cascade_skip.add(parent)
                    queue.append(parent)

        return cascade_skip


class FKSafeCharsetChanger:
    """FK ì•ˆì „ Charset ë³€ê²½ê¸°

    Error 3780 ë°©ì§€ë¥¼ ìœ„í•´ FKë¥¼ ì„ì‹œ DROP í›„ charset ë³€ê²½, ë‹¤ì‹œ FK ì¬ìƒì„±í•©ë‹ˆë‹¤.

    ë¬¸ì œ: SET FOREIGN_KEY_CHECKS = 0ì€ ë°ì´í„° ì‚½ì… ì‹œ FK ê²€ì¦ë§Œ ë¹„í™œì„±í™”.
    ê¸°ì¡´ FK ì œì•½ì¡°ê±´ì˜ ì»¬ëŸ¼ íƒ€ì… í˜¸í™˜ì„± ê²€ì‚¬ëŠ” ì—¬ì „íˆ ë™ì‘í•¨.

    í•´ê²°:
    1. FK ì„ì‹œ DROP (ì˜í–¥ë°›ëŠ” ëª¨ë“  FK)
    2. CONVERT TO CHARACTER SET (ìœ„ìƒ ì •ë ¬: ë¶€ëª¨ ë¨¼ì €)
    3. FK ì¬ìƒì„± (ì›ë˜ ì •ì˜ëŒ€ë¡œ)
    """

    def __init__(self, connector: MySQLConnector, schema: str):
        self.connector = connector
        self.schema = schema
        self._fk_graph_builder: Optional[CollationFKGraphBuilder] = None

    def _get_fk_graph_builder(self) -> CollationFKGraphBuilder:
        """FK ê·¸ë˜í”„ ë¹Œë” (lazy init)"""
        if self._fk_graph_builder is None:
            self._fk_graph_builder = CollationFKGraphBuilder(self.connector, self.schema)
            self._fk_graph_builder.build_graph()
        return self._fk_graph_builder

    def get_related_fks(self, tables: Set[str]) -> List[FKDefinition]:
        """ëŒ€ìƒ í…Œì´ë¸”ê³¼ ì—°ê´€ëœ ëª¨ë“  FK ì •ì˜ ì¡°íšŒ

        Args:
            tables: ëŒ€ìƒ í…Œì´ë¸” ì§‘í•©

        Returns:
            FKDefinition ëª©ë¡ (ë³µí•© FKëŠ” ORDINAL_POSITIONìœ¼ë¡œ ê·¸ë£¹í™”)

        Note: VIEWëŠ” FK ê´€ê³„ ëŒ€ìƒì—ì„œ ì œì™¸ (BASE TABLEë§Œ í¬í•¨)
        """
        if not tables:
            return []

        # í…Œì´ë¸” ëª©ë¡ì„ IN ì ˆì—ì„œ ì‚¬ìš©
        placeholders = ", ".join(["%s"] * len(tables))

        query = f"""
        SELECT
            kcu.CONSTRAINT_NAME,
            kcu.TABLE_NAME,
            kcu.COLUMN_NAME,
            kcu.REFERENCED_TABLE_NAME,
            kcu.REFERENCED_COLUMN_NAME,
            kcu.ORDINAL_POSITION,
            rc.DELETE_RULE,
            rc.UPDATE_RULE
        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu
        JOIN INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS rc
            ON kcu.CONSTRAINT_NAME = rc.CONSTRAINT_NAME
            AND kcu.TABLE_SCHEMA = rc.CONSTRAINT_SCHEMA
        JOIN INFORMATION_SCHEMA.TABLES t_child
            ON kcu.TABLE_NAME = t_child.TABLE_NAME
            AND kcu.TABLE_SCHEMA = t_child.TABLE_SCHEMA
        JOIN INFORMATION_SCHEMA.TABLES t_parent
            ON kcu.REFERENCED_TABLE_NAME = t_parent.TABLE_NAME
            AND kcu.TABLE_SCHEMA = t_parent.TABLE_SCHEMA
        WHERE kcu.TABLE_SCHEMA = %s
            AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
            AND t_child.TABLE_TYPE = 'BASE TABLE'
            AND t_parent.TABLE_TYPE = 'BASE TABLE'
            AND (kcu.TABLE_NAME IN ({placeholders}) OR kcu.REFERENCED_TABLE_NAME IN ({placeholders}))
        ORDER BY kcu.CONSTRAINT_NAME, kcu.ORDINAL_POSITION
        """

        params = [self.schema] + list(tables) + list(tables)
        rows = self.connector.execute(query, tuple(params))

        # ë³µí•© FK ê·¸ë£¹í™”
        fk_map: Dict[str, FKDefinition] = {}

        for row in rows:
            constraint_name = row['CONSTRAINT_NAME']

            if constraint_name not in fk_map:
                fk_map[constraint_name] = FKDefinition(
                    constraint_name=constraint_name,
                    table_name=row['TABLE_NAME'],
                    columns=[],
                    ref_table=row['REFERENCED_TABLE_NAME'],
                    ref_columns=[],
                    on_delete=row['DELETE_RULE'] or 'RESTRICT',
                    on_update=row['UPDATE_RULE'] or 'RESTRICT'
                )

            fk_map[constraint_name].columns.append(row['COLUMN_NAME'])
            fk_map[constraint_name].ref_columns.append(row['REFERENCED_COLUMN_NAME'])

        return list(fk_map.values())

    def generate_safe_charset_sql(
        self,
        tables: Set[str],
        charset: str = "utf8mb4",
        collation: str = "utf8mb4_unicode_ci"
    ) -> Dict[str, List[str]]:
        """FK ì•ˆì „ Charset ë³€ê²½ SQL ìƒì„±

        Args:
            tables: ë³€ê²½í•  í…Œì´ë¸” ì§‘í•©
            charset: ëª©í‘œ charset
            collation: ëª©í‘œ collation

        Returns:
            Dict with keys: 'drop_fks', 'alter_tables', 'add_fks', 'full_sql'
        """
        # 1. ì—°ê´€ FK ì¡°íšŒ
        fks = self.get_related_fks(tables)

        # 2. ìœ„ìƒ ì •ë ¬ (ë¶€ëª¨ ë¨¼ì €)
        fk_builder = self._get_fk_graph_builder()
        ordered_tables = fk_builder.get_topological_order(tables)

        # 3. SQL ìƒì„±
        drop_fks = []
        add_fks = []

        for fk in fks:
            drop_fks.append(fk.get_drop_sql(self.schema))
            add_fks.append(fk.get_add_sql(self.schema))

        alter_tables = []
        for table in ordered_tables:
            alter_tables.append(
                f"ALTER TABLE `{self.schema}`.`{table}` "
                f"CONVERT TO CHARACTER SET {charset} COLLATE {collation};"
            )

        # 4. ì „ì²´ SQL ì¡°í•©
        full_sql = []
        full_sql.append("-- ===== Phase 1: FK ì„ì‹œ DROP =====")
        if drop_fks:
            full_sql.extend(drop_fks)
        else:
            full_sql.append("-- (ì—°ê´€ FK ì—†ìŒ)")

        full_sql.append("")
        full_sql.append("-- ===== Phase 2: Charset ë³€ê²½ (ë¶€ëª¨ ë¨¼ì €) =====")
        full_sql.extend(alter_tables)

        full_sql.append("")
        full_sql.append("-- ===== Phase 3: FK ì¬ìƒì„± =====")
        if add_fks:
            full_sql.extend(add_fks)
        else:
            full_sql.append("-- (ì¬ìƒì„±í•  FK ì—†ìŒ)")

        return {
            'drop_fks': drop_fks,
            'alter_tables': alter_tables,
            'add_fks': add_fks,
            'full_sql': full_sql,
            'fk_count': len(fks),
            'table_count': len(ordered_tables)
        }

    def execute_safe_charset_change(
        self,
        tables: Set[str],
        charset: str = "utf8mb4",
        collation: str = "utf8mb4_unicode_ci",
        dry_run: bool = True,
        progress_callback: Optional[Callable[[str], None]] = None
    ) -> Tuple[bool, str, Dict]:
        """FK ì•ˆì „ Charset ë³€ê²½ ì‹¤í–‰

        Args:
            tables: ë³€ê²½í•  í…Œì´ë¸” ì§‘í•©
            charset: ëª©í‘œ charset
            collation: ëª©í‘œ collation
            dry_run: Trueë©´ SQLë§Œ ìƒì„±
            progress_callback: ì§„í–‰ ë¡œê·¸ ì½œë°±

        Returns:
            (success, message, result_dict)

        ë¡¤ë°± SQL ìƒì„± ê·œì¹™:
        - ê° SQL ì‹¤í–‰ ì§í›„ í•´ë‹¹ ë¡¤ë°± SQLì„ ìŠ¤íƒì— push (LIFO)
        - ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤íƒì„ ì—­ìˆœìœ¼ë¡œ popí•˜ì—¬ ë¡¤ë°± SQL ì œê³µ
        """
        def log(msg: str):
            if progress_callback:
                progress_callback(msg)

        sql_parts = self.generate_safe_charset_sql(tables, charset, collation)

        if dry_run:
            log(f"ğŸ“‹ [DRY-RUN] FK ì•ˆì „ Charset ë³€ê²½ SQL ìƒì„± ì™„ë£Œ")
            log(f"   - ì˜í–¥ë°›ëŠ” FK: {sql_parts['fk_count']}ê°œ")
            log(f"   - ë³€ê²½í•  í…Œì´ë¸”: {sql_parts['table_count']}ê°œ")
            return True, "DRY-RUN ì™„ë£Œ", sql_parts

        # ì‹¤ì œ ì‹¤í–‰
        log("ğŸ”§ FK ì•ˆì „ Charset ë³€ê²½ ì‹œì‘...")

        executed_drop = []
        executed_alter = []
        executed_add = []

        # ë¡¤ë°± SQL ìŠ¤íƒ (LIFO - ì‹¤í–‰ ì—­ìˆœìœ¼ë¡œ ë³µì›)
        rollback_stack: List[str] = []

        # FK ì •ë³´ ë§µ (DROP SQL -> FK ì •ì˜) - ë¡¤ë°± ì‹œ FK ì¬ìƒì„±ìš©
        fk_map: Dict[str, FKDefinition] = {}
        for fk in self.get_related_fks(tables):
            fk_map[fk.get_drop_sql(self.schema)] = fk

        try:
            with self.connector.connection.cursor() as cursor:
                # Phase 1: FK DROP
                log("  ğŸ“¦ Phase 1: FK ì„ì‹œ DROP...")
                for sql in sql_parts['drop_fks']:
                    log(f"    ğŸ”¸ {sql[:60]}...")
                    cursor.execute(sql)
                    executed_drop.append(sql)

                    # ë¡¤ë°± ìŠ¤íƒì— FK ADD SQL ì¶”ê°€ (LIFO)
                    if sql in fk_map:
                        rollback_sql = fk_map[sql].get_add_sql(self.schema)
                        rollback_stack.append(rollback_sql)

                self.connector.connection.commit()

                # Phase 2: Charset ë³€ê²½
                log("  ğŸ”„ Phase 2: Charset ë³€ê²½...")
                skipped_tables = []
                for sql in sql_parts['alter_tables']:
                    log(f"    ğŸ”¸ {sql[:60]}...")
                    try:
                        cursor.execute(sql)
                        executed_alter.append(sql)
                    except Exception as alter_error:
                        error_code = getattr(alter_error, 'args', [None])[0]
                        error_msg_inner = str(alter_error)
                        # Error 1347: 'xxx' is not BASE TABLE (VIEWì¸ ê²½ìš°)
                        if error_code == 1347 or 'is not BASE TABLE' in error_msg_inner:
                            log(f"    â­ï¸ VIEW ê±´ë„ˆë›°ê¸°: {error_msg_inner}")
                            skipped_tables.append(sql)
                            continue
                        else:
                            # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ raise
                            raise
                self.connector.connection.commit()

                # Phase 3: FK ì¬ìƒì„±
                log("  ğŸ”— Phase 3: FK ì¬ìƒì„±...")
                for sql in sql_parts['add_fks']:
                    log(f"    ğŸ”¸ {sql[:60]}...")
                    cursor.execute(sql)
                    executed_add.append(sql)

                    # FK ì¬ìƒì„± ì™„ë£Œ ì‹œ ë¡¤ë°± ìŠ¤íƒì—ì„œ í•´ë‹¹ í•­ëª© ì œê±°
                    if sql in rollback_stack:
                        rollback_stack.remove(sql)

                self.connector.connection.commit()

            if skipped_tables:
                log(f"âœ… FK ì•ˆì „ Charset ë³€ê²½ ì™„ë£Œ (VIEW {len(skipped_tables)}ê°œ ê±´ë„ˆëœ€)")
            else:
                log("âœ… FK ì•ˆì „ Charset ë³€ê²½ ì™„ë£Œ")
            return True, "ë³€ê²½ ì™„ë£Œ", {
                'executed_drop': executed_drop,
                'executed_alter': executed_alter,
                'executed_add': executed_add,
                'skipped_tables': skipped_tables
            }

        except Exception as e:
            self.connector.connection.rollback()
            error_msg = str(e)
            log(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")

            # ìë™ ë³µêµ¬ ì‹œë„: DROPëœ FK ì¬ìƒì„±
            auto_recovered = False
            auto_recovery_errors = []
            if rollback_stack:
                log("  ğŸ”„ ìë™ ë³µêµ¬ ì‹œë„: DROPëœ FK ì¬ìƒì„± ì¤‘...")
                try:
                    with self.connector.connection.cursor() as recovery_cursor:
                        for recovery_fk_sql in reversed(rollback_stack):
                            try:
                                log(f"    ğŸ”¸ {recovery_fk_sql[:60]}...")
                                recovery_cursor.execute(recovery_fk_sql)
                            except Exception as fk_err:
                                auto_recovery_errors.append(f"{recovery_fk_sql[:40]}: {str(fk_err)[:60]}")
                                log(f"    âŒ FK ë³µêµ¬ ì‹¤íŒ¨: {str(fk_err)[:80]}")
                        self.connector.connection.commit()

                    if not auto_recovery_errors:
                        auto_recovered = True
                        log("  âœ… ìë™ ë³µêµ¬ ì™„ë£Œ: ëª¨ë“  FK ì¬ìƒì„± ì„±ê³µ")
                    else:
                        log(f"  âš ï¸ ë¶€ë¶„ ë³µêµ¬: {len(auto_recovery_errors)}ê°œ FK ë³µêµ¬ ì‹¤íŒ¨")
                except Exception as recovery_err:
                    log(f"  âŒ ìë™ ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {str(recovery_err)[:80]}")
                    auto_recovery_errors.append(f"ì „ì²´ ë³µêµ¬ ì‹¤íŒ¨: {str(recovery_err)[:60]}")

            # ë¡¤ë°± SQL ìƒì„± (ìˆ˜ë™ ë³µêµ¬ìš©)
            recovery_sql = self._build_recovery_sql(
                rollback_stack, executed_drop, executed_alter, executed_add, error_msg
            )

            if auto_recovered:
                log(f"  âœ… ìë™ ë³µêµ¬ ì™„ë£Œ - ìˆ˜ë™ ë¡¤ë°± SQL ë¶ˆí•„ìš”")
            else:
                log(f"  ğŸ“‹ ìˆ˜ë™ ë¡¤ë°± SQL {len(rollback_stack)}ê°œ ìƒì„±ë¨")

            return False, f"ì˜¤ë¥˜: {error_msg}", {
                'error': error_msg,
                'executed_drop': executed_drop,
                'executed_alter': executed_alter,
                'executed_add': executed_add,
                'recovery_sql': recovery_sql,
                'rollback_stack': rollback_stack,
                'auto_recovered': auto_recovered,
                'auto_recovery_errors': auto_recovery_errors
            }

    def _build_recovery_sql(
        self,
        rollback_stack: List[str],
        executed_drop: List[str],
        executed_alter: List[str],
        executed_add: List[str],
        error_msg: str
    ) -> List[str]:
        """ë¡¤ë°± SQL ìƒì„± (ìŠ¤íƒ ê¸°ë°˜ LIFO)

        Args:
            rollback_stack: ë¡¤ë°± SQL ìŠ¤íƒ (ì—­ìˆœìœ¼ë¡œ ì‹¤í–‰í•´ì•¼ í•¨)
            executed_drop: ì‹¤í–‰ëœ FK DROP SQL ëª©ë¡
            executed_alter: ì‹¤í–‰ëœ ALTER TABLE SQL ëª©ë¡
            executed_add: ì‹¤í–‰ëœ FK ADD SQL ëª©ë¡
            error_msg: ë°œìƒí•œ ì—ëŸ¬ ë©”ì‹œì§€

        Returns:
            ë¡¤ë°± SQL ëª©ë¡ (ì‹¤í–‰ ìˆœì„œëŒ€ë¡œ)
        """
        from datetime import datetime

        recovery_sql = []
        recovery_sql.append("-- " + "=" * 60)
        recovery_sql.append("-- ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™ ìˆ˜ì • ROLLBACK SQL (ìë™ ìƒì„±)")
        recovery_sql.append(f"-- ìŠ¤í‚¤ë§ˆ: {self.schema}")
        recovery_sql.append(f"-- ìƒì„±ì¼ì‹œ: {datetime.now().isoformat()}")
        recovery_sql.append(f"-- ì—ëŸ¬: {error_msg}")
        recovery_sql.append("-- " + "=" * 60)
        recovery_sql.append("")
        recovery_sql.append("-- âš ï¸ ì£¼ì˜: ì´ SQLì„ ì‹¤í–‰í•˜ë©´ ë³€ê²½ ì „ ìƒíƒœë¡œ ë³µì›ë©ë‹ˆë‹¤.")
        recovery_sql.append("-- ì•„ë˜ SQLì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
        recovery_sql.append("")

        # Phase 1: FK ì¬ìƒì„± (DROPëœ FK ë³µì›) - ìŠ¤íƒì„ ì—­ìˆœìœ¼ë¡œ (LIFO)
        if rollback_stack:
            recovery_sql.append("-- ===== FK ì¬ìƒì„± (DROPëœ FK ë³µì›) =====")
            for sql in reversed(rollback_stack):
                recovery_sql.append(sql)
            recovery_sql.append("")

        # ì‹¤í–‰ ìš”ì•½
        recovery_sql.append("-- ===== ì‹¤í–‰ ìš”ì•½ =====")
        recovery_sql.append(f"-- FK DROP ì‹¤í–‰ë¨: {len(executed_drop)}ê°œ")
        recovery_sql.append(f"-- Charset ë³€ê²½ ì‹¤í–‰ë¨: {len(executed_alter)}ê°œ")
        recovery_sql.append(f"-- FK ADD ì‹¤í–‰ë¨: {len(executed_add)}ê°œ")
        recovery_sql.append(f"-- ë³µì› í•„ìš”: {len(rollback_stack)}ê°œ FK")

        return recovery_sql


class BatchFixExecutor:
    """ë°°ì¹˜ ìˆ˜ì • ì‹¤í–‰ê¸°

    íŠ¸ëœì­ì…˜ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì • SQLì„ ì¼ê´„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Dry-run ëª¨ë“œ ì§€ì›.

    ê°œì„ ì‚¬í•­:
    - ë¬¸ìì…‹ ë³€ê²½ ì‹œ FOREIGN_KEY_CHECKS=0ìœ¼ë¡œ ì „ì²´ ê°ì‹¸ê¸°
    - FK ê´€ê³„ì— ë”°ë¥¸ ì‹¤í–‰ ìˆœì„œ ìµœì í™” (ìœ„ìƒ ì •ë ¬)
    """

    def __init__(self, connector: MySQLConnector, schema: str):
        self.connector = connector
        self.schema = schema
        self._progress_callback: Optional[Callable[[str], None]] = None
        self._fk_graph_builder: Optional[CollationFKGraphBuilder] = None

    def set_progress_callback(self, callback: Callable[[str], None]):
        """ì§„í–‰ ì½œë°± ì„¤ì •"""
        self._progress_callback = callback

    def _log(self, message: str):
        """ì§„í–‰ ë¡œê·¸"""
        if self._progress_callback:
            self._progress_callback(message)

    def _get_fk_graph_builder(self) -> CollationFKGraphBuilder:
        """FK ê·¸ë˜í”„ ë¹Œë” (lazy init)"""
        if self._fk_graph_builder is None:
            self._fk_graph_builder = CollationFKGraphBuilder(self.connector, self.schema)
            self._fk_graph_builder.build_graph()
        return self._fk_graph_builder

    def _has_charset_issues(self, steps: List[FixWizardStep]) -> bool:
        """ë¬¸ìì…‹ ì´ìŠˆê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (FK_CHECKS ë¹„í™œì„±í™” í•„ìš” ì—¬ë¶€)

        ì°¸ê³ : COLLATION_FK_SAFE ì „ëµì€ ìì²´ì ìœ¼ë¡œ FKë¥¼ ê´€ë¦¬í•˜ë¯€ë¡œ ì œì™¸
        """
        return any(
            step.issue_type == IssueType.CHARSET_ISSUE
            and step.selected_option
            and step.selected_option.strategy not in (
                FixStrategy.SKIP,
                FixStrategy.COLLATION_FK_SAFE  # FK ì•ˆì „ ë³€ê²½ì€ ìì²´ FK ê´€ë¦¬
            )
            for step in steps
        )

    def _sort_steps_by_fk_order(self, steps: List[FixWizardStep]) -> List[FixWizardStep]:
        """FK ê´€ê³„ì— ë”°ë¼ ì‹¤í–‰ ìˆœì„œ ì •ë ¬ (ë¶€ëª¨ í…Œì´ë¸” ë¨¼ì €)

        ìœ„ìƒ ì •ë ¬ì„ ì‚¬ìš©í•˜ì—¬ FK ì°¸ì¡° ìˆœì„œì— ë§ê²Œ ì •ë ¬í•©ë‹ˆë‹¤.
        ë¶€ëª¨ í…Œì´ë¸”ì´ ë¨¼ì € ë³€ê²½ë˜ì–´ì•¼ ìì‹ í…Œì´ë¸” ë³€ê²½ ì‹œ FK ì¶©ëŒì´ ì¤„ì–´ë“­ë‹ˆë‹¤.
        """
        # ë¬¸ìì…‹ ì´ìŠˆë§Œ ì •ë ¬ ëŒ€ìƒ
        charset_steps = [s for s in steps if s.issue_type == IssueType.CHARSET_ISSUE]
        other_steps = [s for s in steps if s.issue_type != IssueType.CHARSET_ISSUE]

        if not charset_steps:
            return steps

        try:
            fk_builder = self._get_fk_graph_builder()

            # í…Œì´ë¸”ëª… ì¶”ì¶œ (location í˜•ì‹: "schema.table" ë˜ëŠ” "schema.table.column")
            # ì»¬ëŸ¼ ë ˆë²¨ ìŠ¤í…(schema.table.column)ì˜ ê²½ìš° split('.')[-1]ì´ columnëª…ì´ë¯€ë¡œ
            # parts[1]ì„ ì‚¬ìš©í•´ì•¼ ì˜¬ë°”ë¥¸ tableëª…ì„ ì–»ì„ ìˆ˜ ìˆìŒ
            table_to_steps: Dict[str, List[FixWizardStep]] = {}
            for step in charset_steps:
                parts = step.location.split('.')
                table_name = parts[1] if len(parts) >= 2 else parts[0]
                if table_name not in table_to_steps:
                    table_to_steps[table_name] = []
                table_to_steps[table_name].append(step)

            # ìœ„ìƒ ì •ë ¬
            all_tables = set(table_to_steps.keys())
            sorted_tables = fk_builder.get_topological_order(all_tables)

            # ì •ë ¬ëœ ìˆœì„œë¡œ steps ì¬ë°°ì¹˜ (ê°™ì€ í…Œì´ë¸”ì˜ ì—¬ëŸ¬ ìŠ¤í… ëª¨ë‘ í¬í•¨)
            sorted_charset_steps = []
            for table in sorted_tables:
                if table in table_to_steps:
                    sorted_charset_steps.extend(table_to_steps[table])

            # ì •ë ¬ë˜ì§€ ì•Šì€ í…Œì´ë¸” ì¶”ê°€ (FK ê´€ê³„ ì—†ëŠ” í…Œì´ë¸”)
            sorted_set = set(sorted_tables)
            for step in charset_steps:
                parts = step.location.split('.')
                table_name = parts[1] if len(parts) >= 2 else parts[0]
                if table_name not in sorted_set:
                    sorted_charset_steps.append(step)

            self._log(f"  ğŸ“Š FK ê´€ê³„ì— ë”°ë¼ {len(sorted_charset_steps)}ê°œ ìŠ¤í… ì •ë ¬ ì™„ë£Œ")

            return sorted_charset_steps + other_steps

        except Exception as e:
            self._log(f"  âš ï¸ FK ì •ë ¬ ì‹¤íŒ¨, ì›ë³¸ ìˆœì„œ ìœ ì§€: {e}")
            return steps

    @contextmanager
    def _session_guard(
        self,
        has_charset: bool,
        dry_run: bool,
        original_sql_mode: Optional[str]
    ):
        """ì„¸ì…˜ ìƒíƒœ ë³µì›ì„ ë³´ì¥í•˜ëŠ” context manager.

        sql_mode='', FOREIGN_KEY_CHECKS=0 ì„¤ì • ì´í›„ ëª¨ë“  ì‹¤í–‰ ê²½ë¡œë¥¼ ê°ì‹¸
        ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë°˜ë“œì‹œ ë³µì›í•œë‹¤.
        FK_SAFE ë°°ì¹˜, COLLATION_SINGLE ë³‘í•©, ë©”ì¸ for ë£¨í”„ë¥¼ í¬í•¨í•˜ì—¬
        ë‹¨ì¼ ì§„ì…ì ì—ì„œ ì„¸ì…˜ ì •ë¦¬ë¥¼ ë³´ì¥í•œë‹¤.
        """
        try:
            yield
        finally:
            if not dry_run:
                if original_sql_mode is not None:  # ë¹ˆ ë¬¸ìì—´('')ë„ ë³µì› ë³´ì¥
                    self.connector.set_session_sql_mode(original_sql_mode)
            if has_charset and not dry_run:
                self._log("  ğŸ”’ FOREIGN_KEY_CHECKS ë³µì›")
                try:
                    with self.connector.connection.cursor() as cursor:
                        cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
                    self.connector.connection.commit()
                except Exception as e:
                    self._log(f"  âš ï¸ FK_CHECKS ë³µì› ì‹¤íŒ¨: {e}")

    def execute_batch(
        self,
        steps: List[FixWizardStep],
        dry_run: bool = True
    ) -> BatchExecutionResult:
        """ë°°ì¹˜ ì‹¤í–‰

        Args:
            steps: ì‹¤í–‰í•  ìœ„ì €ë“œ ë‹¨ê³„ ëª©ë¡
            dry_run: Trueë©´ ì‹¤ì œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì˜í–¥ í–‰ ì¶”ì •

        Returns:
            BatchExecutionResult

        ê°œì„ ì‚¬í•­:
        - ë¬¸ìì…‹ ì´ìŠˆ í¬í•¨ ì‹œ FOREIGN_KEY_CHECKS=0 ì ìš©
        - FK ê´€ê³„ì— ë”°ë¥¸ ì‹¤í–‰ ìˆœì„œ ìµœì í™”
        - ì‹¤í–‰ ì „ ìƒíƒœ ìº¡ì²˜ ë° Rollback SQL ìƒì„±
        """
        results: List[FixExecutionResult] = []
        success_count = 0
        fail_count = 0
        skip_count = 0
        total_affected = 0
        rollback_sql = ""

        mode = "[DRY-RUN]" if dry_run else "[ì‹¤í–‰]"
        self._log(f"ğŸ”§ {mode} ë°°ì¹˜ ìˆ˜ì • ì‹œì‘ ({len(steps)}ê°œ)")

        # === ì‹¤í–‰ ì „ ìƒíƒœ ìº¡ì²˜ (Rollback SQL ìƒì„±ìš©) ===
        pre_states: Dict[str, Dict[str, Any]] = {}
        if not dry_run:
            self._log("  ğŸ“¸ ë³€ê²½ ì „ ìƒíƒœ ìº¡ì²˜ ì¤‘...")
            rollback_generator = RollbackSQLGenerator(self.connector, self.schema)
            pre_states = self._capture_pre_states(steps, rollback_generator)

        # ë¬¸ìì…‹ ì´ìŠˆ í™•ì¸ ë° FK_CHECKS ë¹„í™œì„±í™”
        has_charset = self._has_charset_issues(steps)
        original_sql_mode = self.connector.get_session_sql_mode()
        if not dry_run:
            # 0000-00-00 ë‚ ì§œê°’ ë¹„êµ/CONVERT ì‹œ strict mode 1292/1525 ì˜¤ë¥˜ ë°©ì§€
            self.connector.set_session_sql_mode('')
        if has_charset and not dry_run:
            self._log("  ğŸ”“ FOREIGN_KEY_CHECKS ë¹„í™œì„±í™” (ë¬¸ìì…‹ ë³€ê²½ìš©)")
            try:
                with self.connector.connection.cursor() as cursor:
                    cursor.execute("SET FOREIGN_KEY_CHECKS = 0")
                self.connector.connection.commit()
            except Exception as e:
                self._log(f"  âš ï¸ FK_CHECKS ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")

        # FK ê´€ê³„ì— ë”°ë¥¸ ì‹¤í–‰ ìˆœì„œ ì •ë ¬
        if has_charset:
            steps = self._sort_steps_by_fk_order(steps)

        with self._session_guard(has_charset, dry_run, original_sql_mode):
            # === COLLATION_FK_SAFE ë°°ì¹˜ ìµœì í™” ===
            # ê°œë³„ ìŠ¤í…ë§ˆë‹¤ FK DROPâ†’ALTERâ†’ADDë¥¼ ë°˜ë³µí•˜ë©´ O(NÂ²) DDL ë°œìƒ.
            # FK í´ëŸ¬ìŠ¤í„°ë³„(related_tables ì§‘í•©ì´ ë™ì¼í•œ ìŠ¤í…ë¼ë¦¬)ë¡œ ê·¸ë£¹í•‘í•˜ì—¬
            # í´ëŸ¬ìŠ¤í„°ë‹¹ execute_safe_charset_changeë¥¼ 1íšŒë§Œ í˜¸ì¶œí•œë‹¤.
            # dry_runë„ ë™ì¼í•˜ê²Œ ë°°ì¹˜ ì²˜ë¦¬í•˜ì—¬ previewì™€ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¼ì¹˜ì‹œí‚¨ë‹¤.
            fk_safe_processed: Set[str] = set()
            fk_safe_steps = [
                s for s in steps
                if s.selected_option and s.selected_option.strategy == FixStrategy.COLLATION_FK_SAFE
            ]
            if fk_safe_steps:
                from collections import defaultdict as _defaultdict
                # ìŠ¤í‚¤ë§ˆë³„ â†’ í´ëŸ¬ìŠ¤í„°ë³„ 2ë‹¨ê³„ ê·¸ë£¹í•‘
                schema_cluster: Dict[str, Dict[frozenset, List[FixWizardStep]]] = _defaultdict(
                    lambda: _defaultdict(list)
                )
                for s in fk_safe_steps:
                    _schema = s.location.split('.')[0] if '.' in s.location else self.schema
                    _cluster_key = frozenset(s.selected_option.related_tables or [])
                    schema_cluster[_schema][_cluster_key].append(s)

                total_clusters = sum(len(v) for v in schema_cluster.values())
                self._log(
                    f"  ğŸ” FK ì•ˆì „ ë³€ê²½ ë°°ì¹˜ ì²˜ë¦¬"
                    f" ({len(fk_safe_steps)}ê°œ ìŠ¤í… â†’ {total_clusters}ê°œ í´ëŸ¬ìŠ¤í„°)..."
                )

                for _schema, cluster_map in schema_cluster.items():
                    for cluster_tables_frozen, cluster_steps in cluster_map.items():
                        cluster_tables = set(cluster_tables_frozen)
                        self._log(
                            f"    ğŸ“¦ í´ëŸ¬ìŠ¤í„° [{_schema}]: {len(cluster_tables)}ê°œ í…Œì´ë¸”,"
                            f" {len(cluster_steps)}ê°œ ìŠ¤í…"
                        )
                        fk_changer = FKSafeCharsetChanger(self.connector, _schema)

                        if dry_run:
                            sql_parts = fk_changer.generate_safe_charset_sql(
                                cluster_tables, "utf8mb4", "utf8mb4_unicode_ci"
                            )
                            fk_success = True
                            fk_msg = (
                                f"DRY-RUN: {sql_parts['fk_count']}ê°œ FK,"
                                f" {sql_parts['table_count']}ê°œ í…Œì´ë¸” ë³€ê²½ ì˜ˆì •"
                            )
                            fk_dict: Dict = {}
                        else:
                            fk_success, fk_msg, fk_dict = fk_changer.execute_safe_charset_change(
                                tables=cluster_tables,
                                charset="utf8mb4",
                                collation="utf8mb4_unicode_ci",
                                dry_run=False,
                                progress_callback=lambda msg: self._log(f"      {msg}")
                            )

                        for s in cluster_steps:
                            fk_safe_processed.add(s.location)
                            results.append(FixExecutionResult(
                                success=fk_success,
                                message=(
                                    "FK ì•ˆì „ ë³€ê²½ ì™„ë£Œ (ë°°ì¹˜)" if fk_success
                                    else f"FK ì•ˆì „ ë³€ê²½ ì‹¤íŒ¨: {fk_msg}"
                                ),
                                sql_executed=s.selected_option.sql_template or "",
                                affected_rows=1 if fk_success else 0,
                                location=s.location,
                                description=s.description
                            ))
                            if fk_success:
                                success_count += 1
                                total_affected += 1
                            else:
                                fail_count += 1

                        if fk_success:
                            self._log(f"    âœ… í´ëŸ¬ìŠ¤í„° ì™„ë£Œ ({len(cluster_tables)}ê°œ í…Œì´ë¸”)")
                        else:
                            self._log(f"    âŒ í´ëŸ¬ìŠ¤í„° ì‹¤íŒ¨: {fk_msg}")

            # === COLLATION_SINGLE ì»¬ëŸ¼ë³„ â†’ í…Œì´ë¸”ë³„ ë³‘í•© ===
            merged_locations: Set[str] = set()

            single_col_steps = [
                s for s in steps
                if (s.selected_option
                    and s.selected_option.strategy == FixStrategy.COLLATION_SINGLE
                    and s.selected_option.modify_clause  # êµ¬ì¡°í™” í•„ë“œ ì¡´ì¬
                    and len(s.location.split('.')) > 2)  # column-level
            ]

            if single_col_steps:
                from collections import defaultdict as _defaultdict2
                table_groups: Dict[tuple, List[FixWizardStep]] = _defaultdict2(list)
                for s in single_col_steps:
                    parts = s.location.split('.')
                    table_groups[(parts[0], parts[1])].append(s)

                for (schema_name, table_name), group_steps in table_groups.items():
                    if len(group_steps) < 2:
                        continue

                    # modify_clause í•„ë“œì—ì„œ ì§ì ‘ ë³‘í•© (regex íŒŒì‹± ë¶ˆí•„ìš”)
                    clauses = [
                        f"MODIFY COLUMN {s.selected_option.modify_clause}"
                        for s in group_steps
                        if s.selected_option and s.selected_option.modify_clause
                    ]
                    if len(clauses) < 2:
                        continue

                    merged_sql = (
                        f"ALTER TABLE `{schema_name}`.`{table_name}`\n  "
                        + ",\n  ".join(clauses) + ";"
                    )

                    self._log(
                        f"  ğŸ“¦ COLLATION_SINGLE ë³‘í•©: `{table_name}` "
                        f"({len(clauses)}ê°œ ì»¬ëŸ¼ â†’ 1ê°œ DDL)"
                    )

                    if dry_run:
                        merge_result = self._estimate_affected_rows(merged_sql, group_steps[0])
                    else:
                        merge_result = self._execute_single(merged_sql)

                    # ë³‘í•© ì‹¤íŒ¨ ì‹œ ê°œë³„ fallback (2-phase bookkeeping: results í™•ì • í›„ merged_locations ê°±ì‹ )
                    if not merge_result.success and not dry_run:
                        self._log(
                            f"  âš ï¸ ë³‘í•© ALTER ì‹¤íŒ¨, ê°œë³„ ì‹¤í–‰ìœ¼ë¡œ fallback: {merge_result.message}"
                        )
                        pending: Set[str] = set()
                        for s in group_steps:
                            fallback_result = self._execute_single(
                                s.selected_option.sql_template or ""
                            )
                            fallback_result.location = s.location
                            results.append(fallback_result)
                            pending.add(s.location)
                            if fallback_result.success:
                                success_count += 1
                                total_affected += fallback_result.affected_rows
                            else:
                                fail_count += 1
                        merged_locations.update(pending)
                        continue

                    # ì„±ê³µ ì‹œ: ê·¸ë£¹ ë‚´ ëª¨ë“  ìŠ¤í… ê²°ê³¼ ê¸°ë¡ (2-phase bookkeeping)
                    pending = set()
                    for idx, s in enumerate(group_steps):
                        results.append(FixExecutionResult(
                            success=merge_result.success,
                            message=merge_result.message + f" (ë³‘í•©: {len(clauses)}ì»¬ëŸ¼)",
                            sql_executed=(
                                merged_sql if idx == 0
                                else f"-- ë³‘í•©ë¨ ({table_name})"
                            ),
                            affected_rows=(
                                merge_result.affected_rows if idx == 0 else 0
                            ),
                            location=s.location,
                            description=s.description
                        ))
                        pending.add(s.location)
                        if merge_result.success:
                            success_count += 1
                            if idx == 0:
                                total_affected += merge_result.affected_rows
                        else:
                            fail_count += 1
                    merged_locations.update(pending)

                    if merge_result.success:
                        self._log(f"    âœ… {table_name} ë³‘í•© ì™„ë£Œ ({len(clauses)}ì»¬ëŸ¼)")

            for i, step in enumerate(steps, 1):
                # ë°°ì¹˜ë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ FK ì•ˆì „ ë³€ê²½ ìŠ¤í… ê±´ë„ˆë›°ê¸°
                if step.location in fk_safe_processed:
                    continue
                # COLLATION_SINGLE ë³‘í•© ì²˜ë¦¬ëœ ìŠ¤í… ê±´ë„ˆë›°ê¸°
                if step.location in merged_locations:
                    continue

                # ê±´ë„ˆë›°ê¸° ì˜µì…˜ í™•ì¸
                if step.selected_option and step.selected_option.strategy == FixStrategy.SKIP:
                    self._log(f"  [{i}/{len(steps)}] â­ï¸ {step.location} - ê±´ë„ˆë›°ê¸°")
                    results.append(FixExecutionResult(
                        success=True,
                        message="ê±´ë„ˆë›°ê¸°",
                        sql_executed="",
                        affected_rows=0,
                        location=step.location,
                        description=step.description
                    ))
                    skip_count += 1
                    continue

                # FK ì•ˆì „ ë³€ê²½ ì „ëµì€ ë°°ì¹˜ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨ (ìœ„ continueë¡œ ë„ë‹¬ ë¶ˆê°€)
                # dry_run=True ì‹œì—ë„ ë°°ì¹˜ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì´ ë¸”ë¡ì€ ë³´ìœ ë§Œ í•¨ (fallback)
                if step.selected_option and step.selected_option.strategy == FixStrategy.COLLATION_FK_SAFE:
                    self._log(f"  [{i}/{len(steps)}] {mode} {step.location} (FK ì•ˆì „ ë³€ê²½ fallback)...")
                    if dry_run:
                        sql = step.selected_option.sql_template or ""
                        result = self._estimate_affected_rows(sql, step)
                    else:
                        result = self._execute_fk_safe_charset_change(step)
                    result.location = step.location
                    results.append(result)
                    if result.success:
                        success_count += 1
                        total_affected += result.affected_rows
                        if result.affected_rows > 0:
                            self._log(f"    âœ… {result.message} ({result.affected_rows}í–‰)")
                        else:
                            self._log(f"    âœ… {result.message}")
                    else:
                        fail_count += 1
                        self._log(f"    âŒ {result.message}")
                    continue

                # SQL ìƒì„±
                sql = step.selected_option.sql_template if step.selected_option else ""
                if not sql or sql.startswith("--"):
                    # ìˆ˜ë™ ì²˜ë¦¬ ì‚¬ìœ : ì„ íƒëœ ì˜µì…˜ì˜ description ë˜ëŠ” step.description ì‚¬ìš©
                    skip_desc = ""
                    if step.selected_option:
                        skip_desc = step.selected_option.description
                    if not skip_desc:
                        skip_desc = step.description
                    self._log(f"  [{i}/{len(steps)}] â­ï¸ {step.location} - ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”: {skip_desc}")
                    results.append(FixExecutionResult(
                        success=True,
                        message="ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”",
                        sql_executed=sql,
                        affected_rows=0,
                        location=step.location,
                        description=skip_desc
                    ))
                    skip_count += 1
                    continue

                # ì‚¬ìš©ì ì…ë ¥ ëŒ€ì²´
                if step.selected_option and step.selected_option.requires_input and step.user_input:
                    sql = sql.replace("{custom_date}", step.user_input)
                    sql = sql.replace("{precision}", step.user_input)

                self._log(f"  [{i}/{len(steps)}] {mode} {step.location}...")

                if dry_run:
                    # Dry-run: COUNT ì¿¼ë¦¬ë¡œ ì˜í–¥ í–‰ ì¶”ì •
                    result = self._estimate_affected_rows(sql, step)
                else:
                    # ì‹¤ì œ ì‹¤í–‰
                    result = self._execute_single(sql)

                # FK ì •ë ¬ í›„ stepâ†”result ë§¤í•‘ ì˜¤ë¥˜ ë°©ì§€: locationì„ resultì— ì§ì ‘ ì €ì¥
                result.location = step.location
                results.append(result)

                if result.success:
                    success_count += 1
                    total_affected += result.affected_rows
                    if result.affected_rows > 0:
                        self._log(f"    âœ… {result.message} ({result.affected_rows}í–‰)")
                    else:
                        self._log(f"    âœ… {result.message}")
                else:
                    fail_count += 1
                    self._log(f"    âŒ {result.message}")

        # === Rollback SQL ìƒì„± ===
        if not dry_run and pre_states:
            self._log("  ğŸ“ Rollback SQL ìƒì„± ì¤‘...")
            try:
                rollback_generator = RollbackSQLGenerator(self.connector, self.schema)
                rollback_sql = rollback_generator.generate_batch_rollback(steps, pre_states)
                self._log("  âœ… Rollback SQL ìƒì„± ì™„ë£Œ")
            except Exception as e:
                self._log(f"  âš ï¸ Rollback SQL ìƒì„± ì‹¤íŒ¨: {e}")
                rollback_sql = f"-- Rollback SQL ìƒì„± ì˜¤ë¥˜: {e}"

        return BatchExecutionResult(
            total_steps=len(steps),
            success_count=success_count,
            fail_count=fail_count,
            skip_count=skip_count,
            results=results,
            total_affected_rows=total_affected,
            rollback_sql=rollback_sql
        )

    def _capture_pre_states(
        self,
        steps: List[FixWizardStep],
        rollback_generator: 'RollbackSQLGenerator'
    ) -> Dict[str, Dict[str, Any]]:
        """ì‹¤í–‰ ì „ ìƒíƒœ ìº¡ì²˜

        Args:
            steps: ì‹¤í–‰í•  ë‹¨ê³„ ëª©ë¡
            rollback_generator: RollbackSQLGenerator ì¸ìŠ¤í„´ìŠ¤

        Returns:
            location -> state ë§µ
        """
        pre_states: Dict[str, Dict[str, Any]] = {}

        for step in steps:
            if not step.selected_option:
                continue

            strategy = step.selected_option.strategy

            # ê±´ë„ˆë›°ê¸°/ìˆ˜ë™ì€ ìº¡ì²˜ ë¶ˆí•„ìš”
            if strategy in (FixStrategy.SKIP, FixStrategy.MANUAL):
                continue

            location = step.location
            location_parts = location.split('.')

            if len(location_parts) < 2:
                continue

            table = location_parts[1]
            column = location_parts[2] if len(location_parts) > 2 else None

            # Collation ê´€ë ¨ ì „ëµ
            if strategy in (
                FixStrategy.COLLATION_SINGLE,
                FixStrategy.COLLATION_FK_CASCADE,
                FixStrategy.COLLATION_FK_SAFE
            ):
                if column:
                    # ì»¬ëŸ¼ ë ˆë²¨
                    pre_states[location] = rollback_generator.capture_column_info(table, column)
                else:
                    # í…Œì´ë¸” ë ˆë²¨
                    pre_states[location] = rollback_generator.capture_table_charset(table)

                    # FK ì¼ê´„ ë³€ê²½ì¸ ê²½ìš° ì—°ê´€ í…Œì´ë¸”ë„ ìº¡ì²˜
                    if strategy in (FixStrategy.COLLATION_FK_CASCADE, FixStrategy.COLLATION_FK_SAFE):
                        related = step.selected_option.related_tables or []
                        for rel_table in related:
                            rel_location = f"{self.schema}.{rel_table}"
                            if rel_location not in pre_states:
                                pre_states[rel_location] = rollback_generator.capture_table_charset(rel_table)

        return pre_states

    def _execute_single(self, sql: str) -> FixExecutionResult:
        """ë‹¨ì¼ SQL ì‹¤í–‰"""
        try:
            # ì—¬ëŸ¬ ë¬¸ì¥ì´ ìˆì„ ìˆ˜ ìˆìŒ (FK_CHECKS ì„¤ì • ë“±)
            statements = [s.strip() for s in sql.split(';') if s.strip()]

            total_affected = 0
            skipped_views = []
            with self.connector.connection.cursor() as cursor:
                for stmt in statements:
                    if not stmt or stmt.startswith('--'):
                        continue
                    try:
                        cursor.execute(stmt)
                        total_affected += cursor.rowcount if cursor.rowcount > 0 else 0
                    except Exception as stmt_error:
                        error_code = getattr(stmt_error, 'args', [None])[0]
                        error_msg = str(stmt_error)
                        # Error 1347: 'xxx' is not BASE TABLE (VIEWì¸ ê²½ìš°)
                        if error_code == 1347 or 'is not BASE TABLE' in error_msg:
                            skipped_views.append(stmt)
                            continue
                        else:
                            raise

                self.connector.connection.commit()

            if skipped_views:
                return FixExecutionResult(
                    success=True,
                    message=f"ì‹¤í–‰ ì™„ë£Œ (VIEW {len(skipped_views)}ê°œ ê±´ë„ˆëœ€)",
                    sql_executed=sql,
                    affected_rows=total_affected
                )

            return FixExecutionResult(
                success=True,
                message="ì‹¤í–‰ ì™„ë£Œ",
                sql_executed=sql,
                affected_rows=total_affected
            )

        except Exception as e:
            self.connector.connection.rollback()
            return FixExecutionResult(
                success=False,
                message=f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                sql_executed=sql,
                error=str(e)
            )

    def _execute_fk_safe_charset_change(self, step: FixWizardStep) -> FixExecutionResult:
        """FK ì•ˆì „ Charset ë³€ê²½ ì‹¤í–‰

        3ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰:
        1. FK DROP
        2. Charset ë³€ê²½
        3. FK ì¬ìƒì„±

        ê° phaseëŠ” ë³„ë„ ì»¤ë°‹í•˜ì—¬ rollback ê°€ëŠ¥ ë²”ìœ„ ì œí•œ.
        """
        if not step.selected_option:
            return FixExecutionResult(
                success=False,
                message="ì„ íƒëœ ì˜µì…˜ì´ ì—†ìŠµë‹ˆë‹¤.",
                sql_executed="",
                error="No option selected"
            )

        sql = step.selected_option.sql_template or ""
        related_tables = set(step.selected_option.related_tables)

        if not related_tables:
            # related_tablesê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì‹¤í–‰ìœ¼ë¡œ fallback
            return self._execute_single(sql)

        # locationì—ì„œ schema ì¶”ì¶œ
        location_parts = step.location.split('.')
        schema = location_parts[0] if location_parts else self.schema

        # FKSafeCharsetChanger ì‚¬ìš©
        changer = FKSafeCharsetChanger(self.connector, schema)

        self._log("    ğŸ” FK ì•ˆì „ Charset ë³€ê²½ ì‹œì‘...")

        success, message, result_dict = changer.execute_safe_charset_change(
            tables=related_tables,
            charset="utf8mb4",
            collation="utf8mb4_unicode_ci",
            dry_run=False,
            progress_callback=lambda msg: self._log(f"      {msg}")
        )

        if success:
            return FixExecutionResult(
                success=True,
                message="FK ì•ˆì „ ë³€ê²½ ì™„ë£Œ",
                sql_executed=sql,
                affected_rows=len(related_tables)
            )
        else:
            # ë³µì› SQLì´ ìˆìœ¼ë©´ ë©”ì‹œì§€ì— í¬í•¨
            recovery_info = ""
            if 'recovery_sql' in result_dict and result_dict['recovery_sql']:
                recovery_info = "\në³µì› SQL:\n" + "\n".join(result_dict['recovery_sql'])

            return FixExecutionResult(
                success=False,
                message=f"FK ì•ˆì „ ë³€ê²½ ì‹¤íŒ¨: {message}{recovery_info}",
                sql_executed=sql,
                error=result_dict.get('error', message)
            )

    def _estimate_affected_rows(self, sql: str, step: FixWizardStep) -> FixExecutionResult:
        """ì˜í–¥ í–‰ ì¶”ì • (Dry-runìš©)

        UPDATE/DELETE ë¬¸ì„ COUNT ì¿¼ë¦¬ë¡œ ë³€í™˜
        """
        try:
            sql_upper = sql.upper()

            # UPDATE ë¬¸ ì²˜ë¦¬
            if 'UPDATE' in sql_upper and 'WHERE' in sql_upper:
                # UPDATE table SET ... WHERE condition â†’ SELECT COUNT(*) FROM table WHERE condition
                # ê°„ë‹¨í•œ íŒŒì‹±
                where_idx = sql.upper().find('WHERE')
                from_idx = sql.upper().find('UPDATE') + 6
                set_idx = sql.upper().find('SET')

                table_part = sql[from_idx:set_idx].strip()
                where_clause = sql[where_idx:]

                count_sql = f"SELECT COUNT(*) as cnt FROM {table_part} {where_clause}"
                # ì„¸ë¯¸ì½œë¡  ì œê±°
                count_sql = count_sql.rstrip(';')

                # 0000-00-00 ë‚ ì§œê°’ì´ ìˆì„ ê²½ìš° strict modeì—ì„œ COUNT ì¿¼ë¦¬ê°€ ì‹¤íŒ¨í•˜ë¯€ë¡œ
                # ì„ì‹œë¡œ sql_modeë¥¼ ì™„í™”í•œ ë’¤ ì‹¤í–‰í•˜ê³  ë³µì›í•œë‹¤
                _saved_mode: Optional[str] = None
                try:
                    _saved_mode = self.connector.get_session_sql_mode()
                    self.connector.set_session_sql_mode('')
                except Exception:
                    pass  # ëª¨ë“œ ì¡°íšŒ/ì„¤ì • ì‹¤íŒ¨ ì‹œ í˜„ì¬ ëª¨ë“œë¡œ ì‹œë„

                try:
                    result = self.connector.execute(count_sql)
                    affected = result[0]['cnt'] if result else 0
                    count_ok = True
                except Exception:
                    affected = 0
                    count_ok = False
                finally:
                    if _saved_mode is not None:
                        try:
                            self.connector.set_session_sql_mode(_saved_mode)
                        except Exception:
                            pass

                if not count_ok:
                    return FixExecutionResult(
                        success=True,
                        message="[DRY-RUN] ì˜ˆìƒ ì˜í–¥ í–‰: â‰¥1 (0000-00-00 ë“± ë¹„í‘œì¤€ ê°’ í¬í•¨ìœ¼ë¡œ ì •í™•í•œ ìˆ˜ ë¶ˆëª…)",
                        sql_executed=sql,
                        affected_rows=1
                    )

                return FixExecutionResult(
                    success=True,
                    message=f"[DRY-RUN] ì˜ˆìƒ ì˜í–¥ í–‰: {affected:,}",
                    sql_executed=sql,
                    affected_rows=affected
                )

            # ALTER TABLE ë“± DDLì€ ì˜í–¥ í–‰ ì¶”ì • ë¶ˆê°€
            elif 'ALTER' in sql_upper:
                return FixExecutionResult(
                    success=True,
                    message="[DRY-RUN] DDL ë¬¸ - ì˜í–¥ í–‰ ì¶”ì • ë¶ˆê°€",
                    sql_executed=sql,
                    affected_rows=0
                )

            else:
                return FixExecutionResult(
                    success=True,
                    message="[DRY-RUN] ë¶„ì„ ì™„ë£Œ",
                    sql_executed=sql,
                    affected_rows=0
                )

        except Exception as e:
            return FixExecutionResult(
                success=False,
                message=f"[DRY-RUN] ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                sql_executed=sql,
                error=str(e)
            )


class RollbackSQLGenerator:
    """Rollback SQL ìƒì„±ê¸°

    DDL(ALTER TABLE)ì€ auto-commitë˜ë¯€ë¡œ íŠ¸ëœì­ì…˜ ë¡¤ë°±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    ëŒ€ì‹  ë³€ê²½ ì „ ìƒíƒœë¥¼ ê¸°ë¡í•˜ê³ , ì›ë˜ ìƒíƒœë¡œ ë˜ëŒë¦¬ëŠ” SQLì„ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, connector: MySQLConnector, schema: str):
        self.connector = connector
        self.schema = schema
        # ë³€ê²½ ì „ ìƒíƒœ ìºì‹œ
        self._table_charset_cache: Dict[str, Dict[str, str]] = {}
        self._column_info_cache: Dict[str, Dict[str, Any]] = {}

    @staticmethod
    def _format_default_clause(col_info: Dict[str, Any]) -> str:
        """COLUMN_DEFAULT ê°’ â†’ DEFAULT ì ˆ ë¬¸ìì—´ ìƒì„±

        INFORMATION_SCHEMA.COLUMNSì˜ COLUMN_DEFAULTëŠ” ë¬¸ìì—´/Noneìœ¼ë¡œ ì €ì¥ë¨.
        íƒ€ì…ì— ë”°ë¼ ë”°ì˜´í‘œ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ê³ , MySQL í•¨ìˆ˜/í‘œí˜„ì‹ì€ ë”°ì˜´í‘œ ì—†ì´ ì¶œë ¥.
        """
        default_val = col_info.get('COLUMN_DEFAULT')
        col_type = (col_info.get('COLUMN_TYPE') or '').upper()
        nullable = col_info.get('IS_NULLABLE') == 'YES'

        if default_val is None:
            return 'DEFAULT NULL' if nullable else ''

        # MySQL í•¨ìˆ˜/í‘œí˜„ì‹ â†’ ë”°ì˜´í‘œ ì—†ì´
        unquoted_keywords = {
            'CURRENT_TIMESTAMP', 'CURRENT_DATE', 'CURRENT_TIME',
            'NOW', 'NOW()', 'UUID', 'UUID()', 'LOCALTIME', 'LOCALTIMESTAMP',
        }
        stripped = default_val.upper().rstrip('()')
        if stripped in unquoted_keywords:
            return f'DEFAULT {default_val}'

        # ìˆ«ìí˜• â†’ ë”°ì˜´í‘œ ì—†ì´
        numeric_prefixes = (
            'INT', 'TINYINT', 'SMALLINT', 'MEDIUMINT', 'BIGINT',
            'DECIMAL', 'FLOAT', 'DOUBLE', 'NUMERIC', 'BIT', 'YEAR', 'BOOL',
        )
        if any(col_type.startswith(t) for t in numeric_prefixes):
            return f'DEFAULT {default_val}'

        # ë¬¸ìì—´/ê¸°íƒ€ â†’ ì‘ì€ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸° (ë‚´ë¶€ ' ì´ìŠ¤ì¼€ì´í”„)
        escaped = default_val.replace("'", "''")
        return f"DEFAULT '{escaped}'"

    @staticmethod
    def _format_extra_clause(col_info: Dict[str, Any]) -> str:
        """EXTRA í•„ë“œ â†’ SQL ì ˆ ìƒì„± (AUTO_INCREMENT, ON UPDATE ë“±)

        'DEFAULT_GENERATED' ë“± ë‚´ë¶€ ë§ˆí‚¹ì€ ìƒëµí•˜ê³  ìœ ì˜ë¯¸í•œ ì†ì„±ë§Œ ì¶œë ¥.
        """
        extra = (col_info.get('EXTRA') or '').lower()
        if not extra:
            return ''
        parts = []
        if 'auto_increment' in extra:
            parts.append('AUTO_INCREMENT')
        if 'on update current_timestamp' in extra:
            parts.append('ON UPDATE CURRENT_TIMESTAMP')
        return ' '.join(parts)

    def capture_table_charset(self, table: str) -> Dict[str, str]:
        """í…Œì´ë¸”ì˜ í˜„ì¬ charset/collation ìº¡ì²˜"""
        cache_key = f"{self.schema}.{table}"
        if cache_key in self._table_charset_cache:
            return self._table_charset_cache[cache_key]

        query = """
        SELECT
            TABLE_NAME,
            TABLE_COLLATION,
            CCSA.CHARACTER_SET_NAME as TABLE_CHARSET
        FROM INFORMATION_SCHEMA.TABLES T
        LEFT JOIN INFORMATION_SCHEMA.COLLATION_CHARACTER_SET_APPLICABILITY CCSA
            ON T.TABLE_COLLATION = CCSA.COLLATION_NAME
        WHERE T.TABLE_SCHEMA = %s AND T.TABLE_NAME = %s
        """
        result = self.connector.execute(query, (self.schema, table))

        if result:
            info = {
                'charset': result[0]['TABLE_CHARSET'] or 'utf8mb3',
                'collation': result[0]['TABLE_COLLATION'] or 'utf8mb3_general_ci'
            }
        else:
            info = {'charset': 'utf8mb3', 'collation': 'utf8mb3_general_ci'}

        self._table_charset_cache[cache_key] = info
        return info

    def _get_fk_sql_for_tables(self, schema: str, tables: List[str]) -> Tuple[List[str], List[str]]:
        """ëŒ€ìƒ í…Œì´ë¸”ì˜ FK DROP/ADD SQL ì¡°íšŒ

        Returns:
            (drop_sqls, add_sqls) íŠœí”Œ
        """
        if not tables or not self.connector:
            return [], []

        placeholders = ", ".join(["%s"] * len(tables))
        query = f"""
        SELECT
            kcu.CONSTRAINT_NAME,
            kcu.TABLE_NAME,
            kcu.COLUMN_NAME,
            kcu.REFERENCED_TABLE_NAME,
            kcu.REFERENCED_COLUMN_NAME,
            kcu.ORDINAL_POSITION,
            rc.DELETE_RULE,
            rc.UPDATE_RULE
        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu
        JOIN INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS rc
            ON kcu.CONSTRAINT_NAME = rc.CONSTRAINT_NAME
            AND kcu.TABLE_SCHEMA = rc.CONSTRAINT_SCHEMA
        WHERE kcu.TABLE_SCHEMA = %s
            AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
            AND (kcu.TABLE_NAME IN ({placeholders}) OR kcu.REFERENCED_TABLE_NAME IN ({placeholders}))
        ORDER BY kcu.TABLE_NAME, kcu.CONSTRAINT_NAME, kcu.ORDINAL_POSITION
        """
        try:
            params = (schema,) + tuple(tables) + tuple(tables)
            rows = self.connector.execute(query, params)
        except Exception:
            return [], []

        # ë³µí•© FK ê·¸ë£¹í™”
        fk_map: Dict[str, Dict[str, Any]] = {}
        for row in rows:
            key = f"{row['TABLE_NAME']}.{row['CONSTRAINT_NAME']}"
            if key not in fk_map:
                fk_map[key] = {
                    'constraint': row['CONSTRAINT_NAME'],
                    'table': row['TABLE_NAME'],
                    'columns': [],
                    'ref_table': row['REFERENCED_TABLE_NAME'],
                    'ref_columns': [],
                    'on_delete': row.get('DELETE_RULE', 'RESTRICT'),
                    'on_update': row.get('UPDATE_RULE', 'RESTRICT'),
                }
            fk_map[key]['columns'].append(row['COLUMN_NAME'])
            fk_map[key]['ref_columns'].append(row['REFERENCED_COLUMN_NAME'])

        drop_sqls = []
        add_sqls = []
        for fk in fk_map.values():
            drop_sqls.append(
                f"ALTER TABLE `{schema}`.`{fk['table']}` DROP FOREIGN KEY `{fk['constraint']}`;"
            )
            cols = ", ".join(f"`{c}`" for c in fk['columns'])
            ref_cols = ", ".join(f"`{c}`" for c in fk['ref_columns'])
            add_sqls.append(
                f"ALTER TABLE `{schema}`.`{fk['table']}` ADD CONSTRAINT `{fk['constraint']}` "
                f"FOREIGN KEY ({cols}) REFERENCES `{fk['ref_table']}` ({ref_cols}) "
                f"ON DELETE {fk['on_delete']} ON UPDATE {fk['on_update']};"
            )

        return drop_sqls, add_sqls

    def capture_column_info(self, table: str, column: str) -> Dict[str, Any]:
        """ì»¬ëŸ¼ì˜ í˜„ì¬ ì •ë³´ ìº¡ì²˜ (charset í¬í•¨)"""
        cache_key = f"{self.schema}.{table}.{column}"
        if cache_key in self._column_info_cache:
            return self._column_info_cache[cache_key]

        query = """
        SELECT
            COLUMN_NAME,
            COLUMN_TYPE,
            IS_NULLABLE,
            COLUMN_DEFAULT,
            CHARACTER_SET_NAME,
            COLLATION_NAME,
            EXTRA
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s AND COLUMN_NAME = %s
        """
        result = self.connector.execute(query, (self.schema, table, column))

        if result:
            info = dict(result[0])
        else:
            info = {}

        self._column_info_cache[cache_key] = info
        return info

    def capture_tables_state(self, tables: Set[str]) -> Dict[str, Dict[str, str]]:
        """ì—¬ëŸ¬ í…Œì´ë¸”ì˜ ìƒíƒœ ì¼ê´„ ìº¡ì²˜"""
        states = {}
        for table in tables:
            states[table] = self.capture_table_charset(table)
        return states

    def generate_rollback_sql(
        self,
        step: 'FixWizardStep',
        original_state: Optional[Dict[str, Any]] = None,
        all_pre_states: Optional[Dict[str, Dict[str, Any]]] = None
    ) -> str:
        """ë‹¨ì¼ stepì— ëŒ€í•œ Rollback SQL ìƒì„±

        Args:
            step: ì‹¤í–‰ëœ FixWizardStep
            original_state: ë³€ê²½ ì „ ìƒíƒœ (ì—†ìœ¼ë©´ ìºì‹œì—ì„œ ì¡°íšŒ)
            all_pre_states: ì „ì²´ pre-state ë§µ (FK ì¼ê´„ ë³€ê²½ ì‹œ ì—°ê´€ í…Œì´ë¸” ìƒíƒœ ì¡°íšŒìš©)

        Returns:
            Rollback SQL ë¬¸ìì—´
        """
        if not step.selected_option:
            return ""

        strategy = step.selected_option.strategy

        # ê±´ë„ˆë›°ê¸°/ìˆ˜ë™ ì²˜ë¦¬ëŠ” ë¡¤ë°± ë¶ˆí•„ìš”
        if strategy in (FixStrategy.SKIP, FixStrategy.MANUAL):
            return ""

        location_parts = step.location.split('.')
        if len(location_parts) < 2:
            return ""

        schema = location_parts[0]
        table = location_parts[1]
        column = location_parts[2] if len(location_parts) > 2 else None

        lines = []

        # === ë‚ ì§œ ìˆ˜ì • ë¡¤ë°± ===
        if strategy in (FixStrategy.DATE_TO_NULL, FixStrategy.DATE_TO_MIN, FixStrategy.DATE_TO_CUSTOM):
            lines.append(f"-- âš ï¸ ë‚ ì§œ ê°’ ë¡¤ë°± ë¶ˆê°€")
            lines.append(f"-- ì›ë³¸ ê°’ì´ 0000-00-00ì´ì—ˆìœ¼ë¯€ë¡œ ë³µì›í•  ê°’ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            lines.append(f"-- í…Œì´ë¸”: {table}, ì»¬ëŸ¼: {column}")
            lines.append(f"-- ë°±ì—… ë°ì´í„°ì—ì„œ ë³µì›í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.")
            return "\n".join(lines)

        # === Collation ë¡¤ë°± ===
        if strategy == FixStrategy.COLLATION_SINGLE:
            if column:
                # ì»¬ëŸ¼ ë ˆë²¨ ë¡¤ë°±
                col_info = original_state or self.capture_column_info(table, column)
                if col_info:
                    orig_charset = col_info.get('CHARACTER_SET_NAME', 'utf8mb3')
                    orig_collation = col_info.get('COLLATION_NAME', 'utf8mb3_general_ci')
                    col_type = col_info.get('COLUMN_TYPE', 'VARCHAR(255)')
                    nullable = 'NULL' if col_info.get('IS_NULLABLE') == 'YES' else 'NOT NULL'
                    default_clause = self._format_default_clause(col_info)
                    extra_clause = self._format_extra_clause(col_info)

                    # ì»¬ëŸ¼ ì •ì˜: type nullable [default] [extra] charset collation
                    col_def_parts = [col_type, nullable]
                    if default_clause:
                        col_def_parts.append(default_clause)
                    if extra_clause:
                        col_def_parts.append(extra_clause)
                    col_def_parts.append(
                        f"CHARACTER SET {orig_charset} COLLATE {orig_collation}"
                    )

                    lines.append(f"-- Rollback: {table}.{column} ì»¬ëŸ¼ charset ë³µì›")
                    lines.append(f"-- ì›ë³¸: {orig_charset} / {orig_collation}")
                    lines.append(
                        f"ALTER TABLE `{schema}`.`{table}` "
                        f"MODIFY COLUMN `{column}` {' '.join(col_def_parts)};"
                    )
            else:
                # í…Œì´ë¸” ë ˆë²¨ ë¡¤ë°±
                tbl_info = original_state or self.capture_table_charset(table)
                orig_charset = tbl_info.get('charset', 'utf8mb3')
                orig_collation = tbl_info.get('collation', 'utf8mb3_general_ci')

                lines.append(f"-- Rollback: {table} í…Œì´ë¸” charset ë³µì›")
                lines.append(f"-- ì›ë³¸: {orig_charset} / {orig_collation}")
                lines.append(
                    f"ALTER TABLE `{schema}`.`{table}` "
                    f"CONVERT TO CHARACTER SET {orig_charset} COLLATE {orig_collation};"
                )

        elif strategy in (FixStrategy.COLLATION_FK_CASCADE, FixStrategy.COLLATION_FK_SAFE):
            # FK ì¼ê´„ ë³€ê²½ ë¡¤ë°± - ëª¨ë“  ì—°ê´€ í…Œì´ë¸” ë³µì›
            related_tables = step.selected_option.related_tables or [table]

            lines.append(f"-- Rollback: FK ì—°ê´€ í…Œì´ë¸” ì¼ê´„ charset ë³µì›")
            lines.append(f"-- ëŒ€ìƒ í…Œì´ë¸”: {', '.join(related_tables)}")
            lines.append("")

            # FK ì•ˆì „ ë³€ê²½ê³¼ ë™ì¼í•˜ê²Œ FK DROP â†’ ë³€ê²½ â†’ FK ì¬ìƒì„± êµ¬ì¡°
            # FK SQL ì¡°íšŒ (concrete SQL ìƒì„±)
            drop_sqls, add_sqls = [], []
            if strategy == FixStrategy.COLLATION_FK_SAFE:
                drop_sqls, add_sqls = self._get_fk_sql_for_tables(schema, related_tables)

                lines.append("-- Phase 1: FK ì„ì‹œ DROP")
                if drop_sqls:
                    for sql in drop_sqls:
                        lines.append(sql)
                else:
                    lines.append("-- (FK ì •ì˜ ì¡°íšŒ ì‹¤íŒ¨ - ì›ë³¸ ì‹¤í–‰ ë¡œê·¸ ì°¸ì¡°)")
                lines.append("")

            lines.append("-- Phase 2: Charset ë³µì›")
            for tbl in related_tables:
                # pre-state ìš°ì„  ì‚¬ìš© (ë³€ê²½ ì „ ìƒíƒœ), ì—†ìœ¼ë©´ í˜„ì¬ ìƒíƒœ ìº¡ì²˜ (fallback)
                # í…Œì´ë¸” ë ˆë²¨ í‚¤(schema.table) ë¨¼ì € ì¡°íšŒ, ì—†ìœ¼ë©´ ì»¬ëŸ¼ ë ˆë²¨ í‚¤ë„ íƒìƒ‰
                tbl_location = f"{schema}.{tbl}"
                tbl_info = None
                if all_pre_states:
                    if tbl_location in all_pre_states:
                        tbl_info = all_pre_states[tbl_location]
                    else:
                        # ì»¬ëŸ¼ ë ˆë²¨ í‚¤ ì¤‘ í•´ë‹¹ í…Œì´ë¸” ì†Œì† ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©
                        for key, val in all_pre_states.items():
                            if key.startswith(f"{tbl_location}."):
                                tbl_info = val
                                break
                if tbl_info is None:
                    if original_state and tbl == table:
                        tbl_info = original_state
                    else:
                        tbl_info = self.capture_table_charset(tbl)
                orig_charset = tbl_info.get('charset', 'utf8mb3')
                orig_collation = tbl_info.get('collation', 'utf8mb3_general_ci')

                lines.append(f"-- {tbl}: {orig_charset} / {orig_collation}")
                lines.append(
                    f"ALTER TABLE `{schema}`.`{tbl}` "
                    f"CONVERT TO CHARACTER SET {orig_charset} COLLATE {orig_collation};"
                )

            if strategy == FixStrategy.COLLATION_FK_SAFE:
                lines.append("")
                lines.append("-- Phase 3: FK ì¬ìƒì„±")
                if add_sqls:
                    for sql in add_sqls:
                        lines.append(sql)
                else:
                    lines.append("-- (FK ì •ì˜ ì¡°íšŒ ì‹¤íŒ¨ - ì›ë³¸ ì‹¤í–‰ ë¡œê·¸ ì°¸ì¡°)")

        return "\n".join(lines)

    def generate_batch_rollback(
        self,
        steps: List['FixWizardStep'],
        pre_states: Dict[str, Dict[str, Any]]
    ) -> str:
        """ë°°ì¹˜ ì‹¤í–‰ì— ëŒ€í•œ ì „ì²´ Rollback SQL ìƒì„±

        Args:
            steps: ì‹¤í–‰ëœ FixWizardStep ëª©ë¡
            pre_states: ë³€ê²½ ì „ ìƒíƒœ ë§µ (location -> state)

        Returns:
            ì „ì²´ Rollback SQL ë¬¸ìì—´
        """
        from datetime import datetime

        lines = []
        lines.append("-- " + "=" * 60)
        lines.append("-- ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™ ìˆ˜ì • ROLLBACK SQL")
        lines.append(f"-- ìŠ¤í‚¤ë§ˆ: {self.schema}")
        lines.append(f"-- ìƒì„±ì¼ì‹œ: {datetime.now().isoformat()}")
        lines.append("-- " + "=" * 60)
        lines.append("")
        lines.append("-- âš ï¸ ì£¼ì˜ì‚¬í•­:")
        lines.append("-- 1. ì´ íŒŒì¼ì€ ë³€ê²½ ì „ ìƒíƒœë¡œ ë˜ëŒë¦¬ê¸° ìœ„í•œ SQLì…ë‹ˆë‹¤.")
        lines.append("-- 2. DDL(ALTER TABLE)ì€ íŠ¸ëœì­ì…˜ ë¡¤ë°±ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ")
        lines.append("--    ë¬¸ì œ ë°œìƒ ì‹œ ì´ SQLì„ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
        lines.append("-- 3. ë‚ ì§œ ê°’ ë³€ê²½ì€ ì›ë³¸ ê°’ì„ ì•Œ ìˆ˜ ì—†ì–´ ìë™ ë¡¤ë°±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        lines.append("-- 4. ì‹¤í–‰ ì „ ë°˜ë“œì‹œ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
        lines.append("")
        lines.append("")

        # ì´ë¯¸ ì²˜ë¦¬í•œ í…Œì´ë¸”/ì»¬ëŸ¼ ì¶”ì  (ì¤‘ë³µ ë°©ì§€)
        processed_tables: Set[str] = set()      # í…Œì´ë¸” ë ˆë²¨ ì¤‘ë³µ ë°©ì§€
        processed_locations: Set[str] = set()  # ì»¬ëŸ¼ ë ˆë²¨ COLLATION_SINGLE ì¤‘ë³µ ë°©ì§€
        rollback_count = 0

        for step in steps:
            if not step.selected_option:
                continue

            if step.selected_option.strategy == FixStrategy.SKIP:
                continue

            # ìë™ í¬í•¨ëœ í…Œì´ë¸”ì€ ê±´ë„ˆë›°ê¸° (ì›ë³¸ stepì—ì„œ ì²˜ë¦¬)
            if step.included_by is not None:
                continue

            location = step.location
            location_parts = location.split('.')
            table = location_parts[1] if len(location_parts) > 1 else location
            column = location_parts[2] if len(location_parts) > 2 else None
            strategy = step.selected_option.strategy

            if strategy in (FixStrategy.COLLATION_FK_CASCADE, FixStrategy.COLLATION_FK_SAFE):
                # FK ì¼ê´„ ë³€ê²½: ì—°ê´€ í…Œì´ë¸” ì „ì²´ë¥¼ í…Œì´ë¸” ë‹¨ìœ„ë¡œ ì¤‘ë³µ ë°©ì§€
                tables_to_check = set(step.selected_option.related_tables or [table])
                if tables_to_check & processed_tables:
                    continue
                processed_tables.update(tables_to_check)
            elif strategy == FixStrategy.COLLATION_SINGLE and column:
                # ì»¬ëŸ¼ ë ˆë²¨: ê°™ì€ í…Œì´ë¸”ì˜ ì—¬ëŸ¬ ì»¬ëŸ¼ì´ ê°ê° ë¡¤ë°±ë˜ì–´ì•¼ í•˜ë¯€ë¡œ
                # í…Œì´ë¸” ë‹¨ìœ„ê°€ ì•„ë‹Œ location ì „ì²´ë¥¼ í‚¤ë¡œ ì‚¬ìš©
                if location in processed_locations:
                    continue
                processed_locations.add(location)
            else:
                # í…Œì´ë¸” ë ˆë²¨: í…Œì´ë¸” ë‹¨ìœ„ ì¤‘ë³µ ë°©ì§€
                if table in processed_tables:
                    continue
                processed_tables.add(table)

            # ì›ë³¸ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
            original_state = pre_states.get(location)

            rollback_sql = self.generate_rollback_sql(step, original_state, all_pre_states=pre_states)
            if rollback_sql:
                rollback_count += 1
                lines.append(f"-- [{rollback_count}] {location}")
                lines.append(f"-- ì „ëµ: {step.selected_option.label}")
                lines.append(rollback_sql)
                lines.append("")

        if rollback_count == 0:
            lines.append("-- (ë¡¤ë°± ê°€ëŠ¥í•œ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤)")

        return "\n".join(lines)


@dataclass
class CharsetTableInfo:
    """ë¬¸ìì…‹ ìˆ˜ì • ëŒ€ìƒ í…Œì´ë¸” ì •ë³´

    UIì—ì„œ í…Œì´ë¸” ëª©ë¡ì„ í‘œì‹œí•˜ê³  ê±´ë„ˆë›°ê¸° ì„ íƒì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì •ë³´ í´ë˜ìŠ¤.
    """
    table_name: str
    current_charset: str
    current_collation: str
    fk_parents: List[str]       # ì´ í…Œì´ë¸”ì´ ì°¸ì¡°í•˜ëŠ” ë¶€ëª¨ í…Œì´ë¸”
    fk_children: List[str]      # ì´ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ” ìì‹ í…Œì´ë¸”
    is_original_issue: bool     # ì›ë³¸ ë¶„ì„ ì´ìŠˆì— ìˆëŠ” í…Œì´ë¸”ì¸ì§€
    skip: bool = False          # ê±´ë„ˆë›°ê¸° ì—¬ë¶€


class CharsetFixPlanBuilder:
    """ë¬¸ìì…‹ ìˆ˜ì • ê³„íš ë¹Œë”

    ë¬¸ìì…‹ ì´ìŠˆì— ëŒ€í•´:
    1. ì›ë³¸ ì´ìŠˆ í…Œì´ë¸” + FK ì—°ê´€ í…Œì´ë¸” ì „ì²´ ëª©ë¡ ìƒì„±
    2. ì—°ì‡„ ê±´ë„ˆë›°ê¸° í…Œì´ë¸” ê³„ì‚°
    3. FK ì•ˆì „ ë³€ê²½ SQL ìƒì„± (ë¬´ì¡°ê±´ FK DROP â†’ ë³€ê²½ â†’ FK ì¬ìƒì„±)
    """

    def __init__(
        self,
        connector: MySQLConnector,
        schema: str,
        original_issue_tables: Set[str]
    ):
        """
        Args:
            connector: DB ì—°ê²°
            schema: ìŠ¤í‚¤ë§ˆëª…
            original_issue_tables: ì›ë³¸ ë¶„ì„ì—ì„œ ê²€ì¶œëœ ì´ìŠˆ í…Œì´ë¸” ì§‘í•©
        """
        self.connector = connector
        self.schema = schema
        self.original_issue_tables = original_issue_tables

        # FK ê·¸ë˜í”„ ë¹Œë”
        self._fk_graph_builder: Optional[CollationFKGraphBuilder] = None

        # í…Œì´ë¸” ì •ë³´ ìºì‹œ
        self._table_info_cache: Dict[str, CharsetTableInfo] = {}

    def _get_fk_graph_builder(self) -> CollationFKGraphBuilder:
        """FK ê·¸ë˜í”„ ë¹Œë” (lazy init)"""
        if self._fk_graph_builder is None:
            self._fk_graph_builder = CollationFKGraphBuilder(self.connector, self.schema)
            self._fk_graph_builder.build_graph()
        return self._fk_graph_builder

    def _get_table_charset(self, table: str) -> Tuple[str, str]:
        """í…Œì´ë¸”ì˜ í˜„ì¬ charset/collation ì¡°íšŒ"""
        query = """
        SELECT
            TABLE_COLLATION,
            CCSA.CHARACTER_SET_NAME as TABLE_CHARSET
        FROM INFORMATION_SCHEMA.TABLES T
        LEFT JOIN INFORMATION_SCHEMA.COLLATION_CHARACTER_SET_APPLICABILITY CCSA
            ON T.TABLE_COLLATION = CCSA.COLLATION_NAME
        WHERE T.TABLE_SCHEMA = %s AND T.TABLE_NAME = %s
        """
        result = self.connector.execute(query, (self.schema, table))

        if result:
            charset = result[0]['TABLE_CHARSET'] or 'utf8mb3'
            collation = result[0]['TABLE_COLLATION'] or 'utf8mb3_general_ci'
            return charset, collation
        return 'utf8mb3', 'utf8mb3_general_ci'

    def build_full_table_list(self) -> List[CharsetTableInfo]:
        """ì›ë³¸ ì´ìŠˆ í…Œì´ë¸” + FK ì—°ê´€ í…Œì´ë¸” ì „ì²´ ëª©ë¡ ìƒì„±

        Returns:
            CharsetTableInfo ëª©ë¡ (ìœ„ìƒ ì •ë ¬ ìˆœì„œ)
        """
        fk_builder = self._get_fk_graph_builder()

        # 1. ì›ë³¸ ì´ìŠˆ í…Œì´ë¸”ì˜ ëª¨ë“  FK ì—°ê´€ í…Œì´ë¸” ìˆ˜ì§‘
        all_tables: Set[str] = set()
        for table in self.original_issue_tables:
            all_tables.add(table)
            related = fk_builder.get_related_tables(table)
            all_tables.update(related)

        # 2. ìœ„ìƒ ì •ë ¬ (ë¶€ëª¨ ë¨¼ì €)
        ordered_tables = fk_builder.get_topological_order(all_tables)

        # 3. ê° í…Œì´ë¸” ì •ë³´ ìƒì„±
        result: List[CharsetTableInfo] = []
        for table in ordered_tables:
            if table in self._table_info_cache:
                result.append(self._table_info_cache[table])
                continue

            charset, collation = self._get_table_charset(table)
            parents = list(fk_builder.get_parents(table))
            children = list(fk_builder.get_children(table))

            info = CharsetTableInfo(
                table_name=table,
                current_charset=charset,
                current_collation=collation,
                fk_parents=parents,
                fk_children=children,
                is_original_issue=(table in self.original_issue_tables),
                skip=False
            )
            self._table_info_cache[table] = info
            result.append(info)

        return result

    def get_cascade_skip_tables(self, table_to_skip: str) -> Set[str]:
        """ì—°ì‡„ ê±´ë„ˆë›°ê¸° í…Œì´ë¸” ê³„ì‚°

        íŠ¹ì • í…Œì´ë¸” ê±´ë„ˆë›°ê¸° ì‹œ FK ê´€ê³„ë¡œ ì¸í•´ í•¨ê»˜ ê±´ë„ˆë›°ì–´ì•¼ í•˜ëŠ” í…Œì´ë¸” ëª©ë¡.

        Args:
            table_to_skip: ê±´ë„ˆë›°ê¸°í•  í…Œì´ë¸”

        Returns:
            ì—°ì‡„ì ìœ¼ë¡œ ê±´ë„ˆë›°ì–´ì•¼ í•˜ëŠ” í…Œì´ë¸” ì§‘í•© (table_to_skip ì œì™¸)
        """
        fk_builder = self._get_fk_graph_builder()

        # ì „ì²´ ëŒ€ìƒ í…Œì´ë¸” ëª©ë¡
        target_tables = {info.table_name for info in self.build_full_table_list()}

        return fk_builder.get_cascade_skip_tables(table_to_skip, target_tables)

    def generate_fix_sql(
        self,
        tables_to_fix: Set[str],
        charset: str = "utf8mb4",
        collation: str = "utf8mb4_unicode_ci"
    ) -> Dict[str, Any]:
        """FK ì•ˆì „ ë³€ê²½ SQL ìƒì„±

        ë¬´ì¡°ê±´ FK DROP â†’ charset ë³€ê²½ â†’ FK ì¬ìƒì„± ë°©ì‹ ì‚¬ìš©.

        Args:
            tables_to_fix: ë³€ê²½í•  í…Œì´ë¸” ì§‘í•©
            charset: ëª©í‘œ charset
            collation: ëª©í‘œ collation

        Returns:
            Dict with keys: 'drop_fks', 'alter_tables', 'add_fks', 'full_sql', 'fk_count', 'table_count'
        """
        if not tables_to_fix:
            return {
                'drop_fks': [],
                'alter_tables': [],
                'add_fks': [],
                'full_sql': ["-- ë³€ê²½í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤."],
                'fk_count': 0,
                'table_count': 0
            }

        # FKSafeCharsetChanger ì‚¬ìš©
        changer = FKSafeCharsetChanger(self.connector, self.schema)
        return changer.generate_safe_charset_sql(tables_to_fix, charset, collation)


def create_wizard_steps(
    issues: List[Any],
    connector: MySQLConnector,
    schema: str
) -> List[FixWizardStep]:
    """ì´ìŠˆ ëª©ë¡ì—ì„œ ìœ„ì €ë“œ ë‹¨ê³„ ìƒì„±

    Args:
        issues: CompatibilityIssue ëª©ë¡
        connector: DB ì—°ê²°
        schema: ìŠ¤í‚¤ë§ˆëª…

    Returns:
        FixWizardStep ëª©ë¡
    """
    generator = SmartFixGenerator(connector, schema)
    steps = []

    for i, issue in enumerate(issues):
        options = generator.get_fix_options(issue)

        step = FixWizardStep(
            issue_index=i,
            issue_type=issue.issue_type,
            location=issue.location,
            description=issue.description,
            options=options
        )
        steps.append(step)

    return steps
